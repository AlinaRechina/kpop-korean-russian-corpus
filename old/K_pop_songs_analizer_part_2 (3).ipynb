{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Установка библиотек и модулей"
      ],
      "metadata": {
        "id": "6xR9bka-iNdl"
      },
      "id": "6xR9bka-iNdl"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pprint import pprint\n",
        "import xml.etree.ElementTree as ET\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "ko5ARgBQTtqk"
      },
      "id": "ko5ARgBQTtqk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71c7487d",
      "metadata": {
        "id": "71c7487d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dda8ddcf-29a4-4e75-a36a-62c2e7f02cd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: korean_romanizer in /usr/local/lib/python3.7/dist-packages (0.24)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install korean_romanizer\n",
        "from korean_romanizer.romanizer import Romanizer\n",
        "\n",
        "!pip install konlpy\n",
        "from konlpy.tag import Kkma\n",
        "kkma = Kkma()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymystem3 import Mystem\n",
        "m = Mystem()\n",
        "!wget http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
        "!tar -xvf mystem-3.0-linux3.1-64bit.tar.gz\n",
        "!cp mystem /root/.local/bin/mystem"
      ],
      "metadata": {
        "id": "tJP7Ms1F8aYM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed73f953-de91-4401-8a0b-f2c425b4228a"
      },
      "id": "tJP7Ms1F8aYM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-25 16:12:51--  http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
            "Resolving download.cdn.yandex.net (download.cdn.yandex.net)... 5.45.205.245, 5.45.205.244, 5.45.205.242, ...\n",
            "Connecting to download.cdn.yandex.net (download.cdn.yandex.net)|5.45.205.245|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cachev2-spb03.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz?lid=122 [following]\n",
            "--2022-05-25 16:12:52--  https://cachev2-spb03.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz?lid=122\n",
            "Resolving cachev2-spb03.cdn.yandex.net (cachev2-spb03.cdn.yandex.net)... 37.140.137.3, 2a02:6b8:0:2221::303\n",
            "Connecting to cachev2-spb03.cdn.yandex.net (cachev2-spb03.cdn.yandex.net)|37.140.137.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16457938 (16M) [application/octet-stream]\n",
            "Saving to: ‘mystem-3.0-linux3.1-64bit.tar.gz.1’\n",
            "\n",
            "mystem-3.0-linux3.1 100%[===================>]  15.70M  11.7MB/s    in 1.3s    \n",
            "\n",
            "2022-05-25 16:12:54 (11.7 MB/s) - ‘mystem-3.0-linux3.1-64bit.tar.gz.1’ saved [16457938/16457938]\n",
            "\n",
            "mystem\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk==3.6.6\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import wordnet \n",
        "nltk_lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "Lt_6n2bVr8lh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a59197b-db6e-4f23-93f7-697b3fa1c585"
      },
      "id": "Lt_6n2bVr8lh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk==3.6.6 in /usr/local/lib/python3.7/dist-packages (3.6.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.6) (1.1.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.6) (2022.4.24)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.6) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.6) (4.64.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install eng-to-ipa\n",
        "import eng_to_ipa as eti"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdGDIULXlrbj",
        "outputId": "834843e0-bc89-40ce-a707-96cf1ac40316"
      },
      "id": "XdGDIULXlrbj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: eng-to-ipa in /usr/local/lib/python3.7/dist-packages (0.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hangul_string = ''\n",
        "with open('hangul without readings.txt', 'r', encoding = 'utf-8') as han_f:\n",
        "    han_t = han_f.readlines()\n",
        "    for ht in han_t:\n",
        "        hangul_string += ht.strip('\\n')\n",
        "\n",
        "hangul = set(hangul_string) # множество корейских символов"
      ],
      "metadata": {
        "id": "VJrCF9pjKT17"
      },
      "id": "VJrCF9pjKT17",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Открываем .json файл и считываем текст песни"
      ],
      "metadata": {
        "id": "VJArMi-6TuUp"
      },
      "id": "VJArMi-6TuUp"
    },
    {
      "cell_type": "code",
      "source": [
        "#file_name = 'Next Level by aespa (에스파).json'\n",
        "file_name = 'SCIENTIST by TWICE (트와이스).json'\n",
        "with open(file_name, 'r', encoding='utf-8') as f:\n",
        "    song_meta_lyrics = json.load(f)"
      ],
      "metadata": {
        "id": "b-ORbudQTsiy"
      },
      "id": "b-ORbudQTsiy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7bd0be0f",
      "metadata": {
        "id": "7bd0be0f"
      },
      "source": [
        "### Токенизация, определение языка, транслитерация, перевод тегов"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from eng_to_ipa.rhymes import get_rhymes\n",
        "# ПЕРЕВОД\n",
        "\n",
        "light_dict_name = 'kor_rus_dict_light.json'\n",
        "heavy_dict_name = 'kor_rus_dict_heavy.json'\n",
        "\n",
        "ld_f = open(light_dict_name, 'r', encoding='utf-8')\n",
        "ld = json.load(ld_f)\n",
        "\n",
        "hd_f = open(heavy_dict_name, 'r', encoding='utf-8')\n",
        "hd = json.load(hd_f)\n",
        "\n",
        "\n",
        "def definer(word, gr, light_dict, heavy_dict):\n",
        "    # в словаре для экономии времени будут искаться только\n",
        "    # корни, а не вообще любые морфемы\n",
        "    verb_tags = ['V', 'A', 'V, aux', 'A, aux', 'V, cop', 'V, cop, neg', \n",
        "                 'V, ger', 'V, partcp', 'A, partcp']\n",
        "    non_verb_tags = ['S', 'S, aux', 'QUANT', 'NUM', 'ANUM', 'ADV', \n",
        "                     'INTJ', 'PRO']\n",
        "    translation = ''\n",
        "    if gr in verb_tags:\n",
        "        light_translation = light_dict.get(word+'다', ['перевод не найден'])\n",
        "        for tr in light_translation:\n",
        "            translation += tr +'; '\n",
        "        translation = translation.strip('; ')\n",
        "        if translation == 'перевод не найден':\n",
        "            translation = heavy_dict.get(word+'다', 'перевод не найден')\n",
        "    elif gr in non_verb_tags:\n",
        "        light_translation = light_dict.get(word, ['перевод не найден'])\n",
        "        for tr in light_translation:\n",
        "            translation += tr +'; '\n",
        "        translation = translation.strip('; ')\n",
        "        if translation == 'перевод не найден':\n",
        "            translation = heavy_dict.get(word, 'перевод не найден')\n",
        "    \n",
        "    return translation"
      ],
      "metadata": {
        "id": "eZxoxFDszowZ"
      },
      "id": "eZxoxFDszowZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# РАЗБОР KKMA / NLTK\n",
        "\n",
        "def analizer(s):\n",
        "    token_list = []\n",
        "    tokens = kkma.pos(s)\n",
        "    for t in tokens:\n",
        "        if t[1] == 'OL':\n",
        "            lang = 1\n",
        "            transcr = s\n",
        "            gr = nltk.pos_tag([s])[0][1]\n",
        "            return [{'lex':s, 'gr':gr, 'lang':1}]\n",
        "        # а вообще надо сохранять знаки препинания?\n",
        "        # я оставила на всякий случай, но избавиться\n",
        "        # от них очень легко\n",
        "        elif t[1][0] == 'S':\n",
        "            lang = 'none'\n",
        "            transcr = t[0]\n",
        "            gr = 'punct'\n",
        "        else:\n",
        "            lang = 0\n",
        "            gr = t[1]\n",
        "        \n",
        "        token = t[0] # тут можно добавить окончания к предикатам!\n",
        "        token_list.append({'lex':token, 'gr':gr, 'lang':lang})\n",
        "        \n",
        "        \n",
        "    return(token_list)"
      ],
      "metadata": {
        "id": "seKOtZUhipxf"
      },
      "id": "seKOtZUhipxf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ТРАНСЛИТЕРАЦИЯ\n",
        "\n",
        "def transl2(han):\n",
        "    try:\n",
        "        transcr = Romanizer(han)\n",
        "        transcr = transcr.romanize()\n",
        "    except Exception:\n",
        "        transcr = 'transcription_error'\n",
        "    return transcr"
      ],
      "metadata": {
        "id": "un1Um5FoXA77"
      },
      "id": "un1Um5FoXA77",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transl2('녹아버리는 지금 내 기분')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Roa_yy-Fn8iv",
        "outputId": "f5829c22-8f2f-4010-ce47-294efc5a2673"
      },
      "id": "Roa_yy-Fn8iv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'nogabeorineun jigeum nae gibun'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# РАЗДЕЛЕНИЕ СУЩЕСТВИТЕЛЬНЫХ И ЧАСТИЦ\n",
        "\n",
        "def nj_separator(m_list):\n",
        "    # NN_ + JK_ + JK = максимально длинный паттерн\n",
        "    cut = []\n",
        "    just_particles = [\"JK\", \"JKM\", \"JX\", \"JC\"]\n",
        "    for ml in reversed(m_list):\n",
        "        sq = []\n",
        "        if ml['gr'] in just_particles:\n",
        "            sq = [ml['lex'], 'PART', 0, ml['lex']]\n",
        "        elif ml['gr'] == 'JKC':\n",
        "            sq = [ml['lex'], 'PART, nom', 0, ml['lex']]\n",
        "        elif ml['gr'] == 'JKG':\n",
        "            sq = [ml['lex'], 'PART, gen', 0, ml['lex']]\n",
        "        elif ml['gr'] == 'JKO':\n",
        "            sq = [ml['lex'], 'PART, acc', 0, ml['lex']]\n",
        "        elif ml['gr'] == 'NNP' or ml['gr'] == 'NNG':\n",
        "            sq = [ml['lex'], 'S', 0, ml['lex']]\n",
        "        else:\n",
        "            sq = [ml['lex'], 'PART', 0, ml['lex']]\n",
        "        \n",
        "        cut.insert(0, sq)\n",
        "\n",
        "    return cut"
      ],
      "metadata": {
        "id": "ssqyf1_4C9Nt"
      },
      "id": "ssqyf1_4C9Nt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ПЕРЕВОД ТЕГОВ KKMA В СИСТЕМУ НКРЯ, ТРАНСЛИТЕРАЦИЯ И ПЕРЕВОД\n",
        "# fw - словоформа от пробела до пробела\n",
        "# ms - [{'lex':морфема, 'gr':gr, 'lang':0, \n",
        "#        'transl':перевод, 'transcr':транслитерация}]\n",
        "\n",
        "def ncrl(fw, ms):\n",
        "    final_tag = ''\n",
        "    lex = fw\n",
        "\n",
        "    # сначала выпишем все теги, присвоенные kkma\n",
        "    tags = []\n",
        "    mors = []\n",
        "\n",
        "    # оставляем целое слово и его целый разбор\n",
        "    full_word = fw\n",
        "    punctuation_tags = ['SF','SE','SS','SP','SO',\n",
        "                        'SW', 'ON'] # если какие-то не слова всё же попали\n",
        "    \n",
        "    for m in ms:\n",
        "        if m['lang'] == 0:\n",
        "            tags.append(m['gr'])\n",
        "            mors.append(m['lex'])\n",
        "        elif m['lang'] == 1:\n",
        "            return en_ncrl(ms, full_word)\n",
        "        else:\n",
        "            final_tag = (m['gr'])\n",
        "            return [[full_word, final_tag, 3, full_word]]\n",
        "    \n",
        "    if len(mors)>0:\n",
        "        m_lex = mors[0]\n",
        "    else:\n",
        "        m_lex = fw\n",
        "\n",
        "    # проверяем наличие морфем,\n",
        "    # приписывающих часть речи\n",
        "\n",
        "    # деепричастия\n",
        "    if 'EFI' in tags or 'ECE' in tags or 'ECD' in tags and ms[-1]['lex']!='게':\n",
        "        if 'VA' in tags or 'VXA' in tags:\n",
        "            final_tag = 'A, ger'\n",
        "        elif 'VV' in tags or 'VXV' in tags or 'VCP' in tags or 'VCN' in tags:\n",
        "            final_tag = 'V, ger'\n",
        "        return [[full_word, final_tag, 0, m_lex]]\n",
        "    \n",
        "    # причастия\n",
        "    if 'ETD' in tags:\n",
        "        if 'VA' in tags:\n",
        "            final_tag = 'A, partcp'\n",
        "        else:\n",
        "            final_tag = 'V, partcp'\n",
        "        return [[full_word, final_tag, 0, m_lex]]\n",
        "\n",
        "    # номинализация, вербализация и аджективизация\n",
        "    if 'ETN' in tags:\n",
        "        final_tag = 'S'\n",
        "        return [[full_word, final_tag, 0, m_lex]]\n",
        "    \n",
        "    if 'XSN' in tags:\n",
        "        final_tag = 'S'\n",
        "        return [[full_word, final_tag, 0, m_lex]]\n",
        "\n",
        "    if 'XSV' in tags:\n",
        "        final_tag = 'V'\n",
        "        return [[full_word, final_tag, 0, m_lex]]\n",
        "\n",
        "    if 'XSA' in tags:\n",
        "        final_tag = 'A'\n",
        "        return [[full_word, final_tag, 0, m_lex]]\n",
        "\n",
        "    # отглагольные деепричастия\n",
        "    if 'ECD' in tags and ms[-1]['lex']=='게':\n",
        "        final_tag = 'ADV'\n",
        "        return [[full_word, final_tag, 0, lex]]\n",
        "    \n",
        "    # отделение существительных от частиц и падежей\n",
        "    particles = ['JX', 'JKS', 'JKC', 'JKG', 'JKO', 'JKM', 'JC']\n",
        "    for pt in particles:\n",
        "        if pt in tags and 'NNG' in tags or pt in tags and 'NNP' in tags:\n",
        "            return nj_separator(ms)\n",
        "\n",
        "    # приписывание всех остальных тегов\n",
        "    if 'VV' in tags:\n",
        "        final_tag = 'V'\n",
        "        return [[full_word, final_tag, 0, m_lex]]\n",
        "    \n",
        "    if 'VA' in tags or 'MDT' in tags:\n",
        "        final_tag = 'A'\n",
        "        return [[full_word, final_tag, 0, m_lex]]\n",
        "\n",
        "    if 'NNP' in tags or 'NNG' in tags:\n",
        "        final_tag = 'S'\n",
        "        return [[full_word, final_tag, 0, lex]]\n",
        "    \n",
        "    if 'NNB' in tags or 'NNM' in tags:\n",
        "        final_tag = 'S, aux'\n",
        "        return [[full_word, final_tag, 0, lex]]\n",
        "    \n",
        "    if 'NR' in tags:\n",
        "        final_tag = 'NUM'\n",
        "        return [[full_word, final_tag, 0, lex]]\n",
        "    \n",
        "    if 'NP' in tags:\n",
        "        final_tag = 'PRO'\n",
        "        return [[full_word, final_tag, 0, lex]]\n",
        "\n",
        "    if 'VXV' in tags:\n",
        "        final_tag = 'V, aux'\n",
        "        return [[full_word, final_tag, 0, m_lex]]\n",
        "\n",
        "    if 'VXA' in tags:\n",
        "        final_tag = 'A, aux'\n",
        "        return [[full_word, final_tag, 0, lex]]\n",
        "    \n",
        "    if 'VCP' in tags:\n",
        "        final_tag = 'V, cop'\n",
        "        return [[full_word, final_tag, 0, lex]]\n",
        "    \n",
        "    if 'VCN' in tags:\n",
        "        final_tag = 'V, cop, neg'\n",
        "        return [[full_word, final_tag, 0, lex]]\n",
        "    \n",
        "    if 'MDN' in tags:\n",
        "        final_tag = 'ANUM'\n",
        "        return [[full_word, final_tag, 0, lex]]\n",
        "    \n",
        "    if 'MAG' in tags or 'MAC' in tags:\n",
        "        final_tag = 'ADV'\n",
        "        return [[full_word, final_tag, 0, lex]]\n",
        "\n",
        "    if 'IC' in tags:\n",
        "        final_tag = 'INTJ'\n",
        "        return [[full_word, final_tag, 0, lex]]\n",
        "\n",
        "    return [[full_word, final_tag, 3, lex]]"
      ],
      "metadata": {
        "id": "CNY7h8Ffpiqm"
      },
      "id": "CNY7h8Ffpiqm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# эта функция разлепляет contracted forms\n",
        "def uncontract(contracted):\n",
        "    forms = []\n",
        "    annots = {'t':['not','ADV',1], 've':['have','V',1], 'll':['will', 'MD',1],\n",
        "              'd':['would', 'MD',1], 're':['are', 'V',1], 'm':['am', 'V',1]}\n",
        "    pros = ['he', 'she', 'it', 'there', 'here', 'where', 'who', 'that']\n",
        "\n",
        "    parts = contracted.split('\\'')\n",
        "\n",
        "    if contracted == 'let\\'s':\n",
        "        return [['let','V', 1],['us', 'PRO', 1]]\n",
        "\n",
        "    # mustn't've, couldn't've ect\n",
        "    if len(parts) == 3 and parts[-1] == 've':\n",
        "        forms = uncontract(parts[:-1])\n",
        "        forms.append(annots['ve'])\n",
        "        return forms\n",
        "        \n",
        "    # n't\n",
        "    elif parts[-1] == 't':\n",
        "        true_first = parts[0][:-1]\n",
        "        forms.append([true_first, nltk.pos_tag([true_first])[0], 1])\n",
        "        forms.append(annots['t'])\n",
        "        return forms\n",
        "\n",
        "    # 's - генитив или is (has)\n",
        "    elif parts[-1] == 's':\n",
        "        if parts[0] in pros:\n",
        "            forms.append([parts[0], nltk.pos_tag([parts[0]])[0], 1])\n",
        "            forms.append(['is', 'V', 1])\n",
        "            return  forms\n",
        "        else:\n",
        "            return [[contracted, 'S, sg, gen', 1]]\n",
        "\n",
        "    # s' - генитив  множественного \n",
        "    elif parts[-1] == '' and parts[-2][-1] == 's':\n",
        "        return [[contracted, 'S, pl, gen', 1]]\n",
        "\n",
        "    else:\n",
        "        try: \n",
        "            forms.append([parts[0], nltk.pos_tag([parts[0]])[0], 1])\n",
        "            forms.append(annots[parts[-1]])\n",
        "            return forms\n",
        "        except:\n",
        "            return [[contracted, nltk.pos_tag(contracted)[0], 1]]"
      ],
      "metadata": {
        "id": "cHEkqWh2SLxM"
      },
      "id": "cHEkqWh2SLxM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ПЕРЕВОД ТЕГОВ nltk В СИСТЕМУ НКРЯ <-\n",
        "# ems - {'lex':token, 'gr':gr, 'transcr':transcr, 'lang':1}\n",
        "\n",
        "def en_ncrl(ems, full_word):\n",
        "    etags = []\n",
        "\n",
        "    for em in ems:\n",
        "        etags.append(em['gr'])\n",
        "    \n",
        "    # боремся с проблемами с contructed forms, которые возникают из-за\n",
        "    # отсутствия контекста: nltk начинает их парсить как NN все подряд\n",
        "    if '\\'' in em['lex']:\n",
        "        return(uncontract(full_word))\n",
        "\n",
        "    final_tag = '' # на случай, если что-то пошло не так\n",
        "\n",
        "    # переводим в НКРЯ, если это не была contructed form\n",
        "    if 'FW' in etags:\n",
        "        final_tag = 'NONLEX'\n",
        "    if 'UH' in etags:\n",
        "        final_tag = 'INTJ'\n",
        "    if 'IN' in etags:\n",
        "        final_tag = 'PR'\n",
        "    if 'CC' in etags:\n",
        "        final_tag = 'CONJ'\n",
        "    if 'PDT' in etags:\n",
        "        final_tag = 'ANUM'\n",
        "    if 'RP' in etags:\n",
        "        final_tag = 'PART'\n",
        "    if 'DT' in etags:\n",
        "        final_tag = 'ART'\n",
        "    if 'LS' in etags:\n",
        "        final_tag = 'LS'\n",
        "    if 'TO' in etags:\n",
        "        final_tag = 'PART'\n",
        "    if 'WDT' in etags:\n",
        "        final_tag = 'APRO'\n",
        "    if 'WP' in etags or 'PRP' in etags:\n",
        "        final_tag = 'PRO'\n",
        "    if 'WRB' in etags:\n",
        "        final_tag = 'ADVPRO'\n",
        "    if 'PRPS' in etags:\n",
        "        final_tag = 'APRO'\n",
        "    if 'CD' in etags:\n",
        "        final_tag = 'NUM'\n",
        "    if 'EX' in etags or 'RB' in etags:\n",
        "        final_tag = 'ADV'\n",
        "    if 'RBR' in etags:\n",
        "        final_tag = 'ADV, comp'\n",
        "    if 'RBS' in etags:\n",
        "        final_tag = 'ADV, supr'\n",
        "    if 'JJ' in etags:\n",
        "        final_tag = 'ADJ'\n",
        "    if 'JJR' in etags:\n",
        "        final_tag = 'ADJ, comp'\n",
        "    if 'JJS' in etags:\n",
        "        final_tag = 'ADJ, supr'\n",
        "    if 'NN' in etags or 'NNP' in etags:\n",
        "        final_tag = 'S, sg'\n",
        "    if 'NNS' in etags or 'NNPS' in etags:\n",
        "        final_tag = 'S, pl'\n",
        "    if 'VB' in etags:\n",
        "        final_tag = 'V'\n",
        "    if 'VBG' in etags:\n",
        "        final_tag = 'V, ger'\n",
        "    if 'VBD' in etags or 'VBP' in etags:\n",
        "        final_tag = 'V, praet'\n",
        "    if 'VBN' in etags:\n",
        "        final_tag = 'V, partcp'\n",
        "    if 'VBZ' in etags:\n",
        "        final_tag = 'V, praet, 3p, sg'\n",
        "    if 'MD' in etags:\n",
        "        final_tag = 'V'\n",
        "    if 'POS' in etags:\n",
        "        final_tag = 'S, gen' # но по идее эти формы отсекаются раньше\n",
        "\n",
        "    return [[full_word, final_tag, 1]]"
      ],
      "metadata": {
        "id": "X3hVnDUoeXl8"
      },
      "id": "X3hVnDUoeXl8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ТОКЕНИЗАЦИЯ\n",
        "\n",
        "def tag_ana(org, ld, hd):\n",
        "    anas = []\n",
        "    ncrl_token_list = []\n",
        "    toks = org.split(' ')\n",
        "    i_char = 0 # счётчик символов\n",
        "    i_wn = 0 # счётчик слов\n",
        "\n",
        "    for tok in toks:\n",
        "        end_of_the_token = i_char + len(tok) - 1\n",
        "        tok = tok.strip('\\.\\,\\:\\'\\\"\\-\\+\\=\\$\\%\\#\\@\\/\\\\\\[\\]\\{\\}\\(\\)\\*\\&\\^\\`\\~\\n')\n",
        "        done_tok = analizer(tok) # просто обработка kkma или nltk\n",
        "        words = ncrl(tok, done_tok) # объединение морфем + теги нкря\n",
        "        # in words each w = [full_form, ncr_tag, lang, (lex - только для кор)]\n",
        "        \n",
        "        for w in words:\n",
        "            small_ana = {'pos':w[1], 'lang':w[2]}\n",
        "            if small_ana['lang'] == 0:\n",
        "                small_ana['lex'] = w[3]\n",
        "                small_ana['transcr'] = transl2(w[0])\n",
        "                translation = definer(w[3], w[1], ld, hd)\n",
        "                if translation != '':\n",
        "                      small_ana['trans_ru'] = translation\n",
        "            elif small_ana['lang'] == 1:\n",
        "                small_ana['lex'] = nltk_lemmatizer.lemmatize(w[0])\n",
        "\n",
        "            big_ana = {'wf':w[0].lower(), 'wtype':'word', 'ana':small_ana, \n",
        "                       'sentence_index':i_wn, 'off_start':i_char,\n",
        "                       'off_end':end_of_the_token}\n",
        "            if i_wn != len(toks) - 1:\n",
        "                big_ana['next_word'] = i_wn + 1\n",
        "\n",
        "            anas.append(big_ana)\n",
        "            i_wn += 1\n",
        "\n",
        "        i_char = end_of_the_token + 2 # пробел\n",
        "\n",
        "    for a in anas:\n",
        "        a['sentence_index_neg'] = len(anas) - a['sentence_index']\n",
        "        \n",
        "    return anas"
      ],
      "metadata": {
        "id": "8-dBAB_S4kNb"
      },
      "id": "8-dBAB_S4kNb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Обработка русского текста"
      ],
      "metadata": {
        "id": "Ktru55gh8R78"
      },
      "id": "Ktru55gh8R78"
    },
    {
      "cell_type": "code",
      "source": [
        "def rus_tagger(phrase, para_alignment):\n",
        "  # заполняем meta пустыми значениями, т.к. для русского не актуально\n",
        "    para_alignment['off_start'] = 0\n",
        "    para_alignment['off_end'] = len(phrase) - 1\n",
        "    ready = {'text':phrase, 'lang':2, 'para_alignment':para_alignment,\n",
        "             'meta':{'possibly_rhymed_with':'', 'rhymed_with':'',\n",
        "                     'last_word':'', 'ending':'', 'last_vowel':'',\n",
        "                     'length_in_syllables':0}}\n",
        "\n",
        "    words = []\n",
        "    char_i = 0\n",
        "    word_i = 0\n",
        "    \n",
        "    \n",
        "    punct = '\\.\\,\\:\\'\\\"\\-\\+\\=\\$\\%\\#\\@\\/\\\\\\[\\]\\{\\}\\(\\)\\*\\&\\^\\`\\~\\n '\n",
        "    phrase = phrase.strip(punct)\n",
        "    mb_ana = m.analyze(phrase)\n",
        "    m_ana = []\n",
        "    # удалим все пробелы из анализа\n",
        "    for mb in mb_ana:\n",
        "        if mb['text'] != ' ':\n",
        "            m_ana.append(mb)\n",
        "\n",
        "    for m_word in m_ana[:-1]:\n",
        "        if 'analysis' in m_word and len(m_word['analysis'])>0:\n",
        "            gr = m_word['analysis'][0]['gr']\n",
        "            pos = gr.split('=')[0].split(',')[0]\n",
        "            lex = m_word['analysis'][0]['lex']\n",
        "            ana = [{'pos':pos, 'lex':lex}]\n",
        "            word = {'wf':m_word['text'], 'sentence_index_neg':len(m_ana)-word_i,\n",
        "                     'sentence_index':word_i, 'ana':ana, 'wtype':'word',}\n",
        "                \n",
        "        elif 'analysis' in m_word and len(m_word['analysis']) == 0:\n",
        "            word = {'wf':m_word['text'], 'wtype':'word', \n",
        "                    'sentence_index':word_i,\n",
        "                    'sentence_index_neg':len(m_ana)-word_i}\n",
        "           \n",
        "        elif 'analysis' not in m_word:\n",
        "            word = {'wf':m_word['text'], 'wtype':'punct',\n",
        "                    'sentence_index':word_i,\n",
        "                    'sentence_index_neg':len(m_ana)-word_i}\n",
        "            \n",
        "        word_i += 1\n",
        "        if word_i < len(m_ana):\n",
        "                word['next_word'] = word_i\n",
        "        \n",
        "        word['off_start'] = char_i\n",
        "        word['off_end'] = char_i + len(m_word['text']) - 1\n",
        "        char_i += + len(m_word['text']) + 1 # помним про пробелы\n",
        "        \n",
        "        words.append(word)\n",
        "\n",
        "    ready['words'] = words\n",
        "    return ready"
      ],
      "metadata": {
        "id": "jVwudD9u8OrB"
      },
      "id": "jVwudD9u8OrB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Стиховедческая разметка"
      ],
      "metadata": {
        "id": "yndSucxzB4DB"
      },
      "id": "yndSucxzB4DB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Рифма"
      ],
      "metadata": {
        "id": "48i0R767D-qF"
      },
      "id": "48i0R767D-qF"
    },
    {
      "cell_type": "code",
      "source": [
        "# ТРАНСЛИТЕРАЦИЯ КОРЕЙСКОГО -> МФА\n",
        "def rom_to_ipa(rom):\n",
        "    \n",
        "    # переводим диграфы согласных в МФА\n",
        "    rom = rom.replace('ng', 'ŋ')\n",
        "    rom = rom.replace('ch', 'ʧʰ')\n",
        "    rom = rom.replace('j', 'ʤ')\n",
        "\n",
        "    vowels = 'euioa'\n",
        "    voiced = 'mnlŋ'\n",
        "    unvoiced = 'ktpʧ'\n",
        "    voiced_paired = 'gdbʤ'\n",
        "    palatalized = 'gkdtbplmrnh'\n",
        "    pairs = {'g':'k', 'd':'t', 'b':'p', 'ʤ':'ʧ'}\n",
        "    \n",
        "    rom = ' ' + rom + ' '\n",
        "    new_rom = ''\n",
        "\n",
        "    for i in range(1,len(rom)-1):\n",
        "        # придыхательные согласные\n",
        "        if rom[i] in unvoiced and rom[i-1] != rom[i] and rom[i+1] != rom[i]:\n",
        "            new_rom += rom[i] + 'ʰ'\n",
        "\n",
        "        # палатализация\n",
        "        elif rom[i] == 'y':\n",
        "            if rom[i-1] == ' ' or rom[i-1] in vowels:\n",
        "                new_rom += 'y'\n",
        "            elif rom[i-1] in palatalized:\n",
        "                new_rom += 'ʲ' \n",
        "\n",
        "        # обычные согласные: \n",
        "        # интервокальная позиция и после звонких -> звонкий\n",
        "        # начало слова, после глухих, конец слова -> глухой\n",
        "        elif rom[i] in voiced_paired:\n",
        "            if rom[i-1] in vowels and rom[i+1] in vowels:\n",
        "                new_rom += rom[i]\n",
        "            elif rom[i-1] in voiced and rom[i+1] in vowels:\n",
        "                new_rom += rom[i]\n",
        "            else:\n",
        "                new_rom += pairs[rom[i]]\n",
        "\n",
        "        # остальное просто перезаписываем\n",
        "        else:\n",
        "            new_rom += rom[i]\n",
        "\n",
        "    # в современном корейском 애 и 에 совпали в ɛ\n",
        "    new_rom = new_rom.replace('ae', 'ɛ')\n",
        "    new_rom = new_rom.replace('oe', 'wɛ')\n",
        "    new_rom = new_rom.replace('eu', 'ɯ')\n",
        "    new_rom = new_rom.replace(' ui', ' ɰi')\n",
        "    new_rom = new_rom.replace('ui', 'i')\n",
        "    new_rom = new_rom.replace('eo', 'ʌ')\n",
        "    new_rom = new_rom.replace('a', 'ɑ')\n",
        "    new_rom = new_rom.replace('e', 'ɛ')\n",
        "\n",
        "    # ui\n",
        "    \n",
        "    return new_rom"
      ],
      "metadata": {
        "id": "Bq9eLjKzP0hw"
      },
      "id": "Bq9eLjKzP0hw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ВЫДЕЛЕНИЕ ПОСЛЕДНЕГО СЛОГА И ПОСЛЕДНЕГО ГЛАСНОГО\n",
        "\n",
        "def ender(transcr):\n",
        "    vowels = 'ɛieuoaɐɤʌɯɔæɶɑɒəʊɜɪ:'\n",
        "    ending = ''\n",
        "    last_vowel = ''\n",
        "    written = 0\n",
        "    for i in range(len(transcr)-1, -1, -1):\n",
        "        if transcr[i] in vowels and written == 0:\n",
        "            last_vowel = transcr[i] + last_vowel\n",
        "            ending = transcr[i] + ending\n",
        "            written = 1\n",
        "        elif transcr[i] in vowels and written == 1:\n",
        "            last_vowel = transcr[i] + last_vowel\n",
        "            ending = transcr[i] + ending\n",
        "        elif transcr[i] in vowels and written == 2:\n",
        "            written = 3\n",
        "        elif transcr[i] not in vowels and written == 0:\n",
        "            ending = transcr[i] + ending\n",
        "        elif transcr[i] not in vowels and transcr[i] != 'ʰ' and transcr[i] != 'ʲ' and written == 1:\n",
        "            ending = transcr[i] + ending\n",
        "            written = 2\n",
        "        elif transcr[i] == 'ʰ' and written < 2:\n",
        "            ending = 'ʰ' + ending\n",
        "        elif transcr[i] == 'ʲ' and written < 2:\n",
        "            ending = 'ʲ' + ending\n",
        "    return last_vowel, ending"
      ],
      "metadata": {
        "id": "IDuEB_pHOfWt"
      },
      "id": "IDuEB_pHOfWt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ДЛЯ POSSIBLY RHYMED\n",
        "\n",
        "rhymed_vowels = {'i':'ɯɪi', 'ɯ':'ɯɪi', 'ɪ':'ɪɯi', \n",
        "                 'u':'uʊ', 'ʊ':'uʊ', 'ə':'ɐ',\n",
        "                 'e':'eæɛ', 'æ':'eæɛ', 'ɛ':'eæɛ',\n",
        "                 'a':'aɐɑ', 'ɐ':'aɐɑə', 'ɑ':'aɐɑ',\n",
        "                 'o':'oɤɔʌ', 'ɤ':'ʌoɤɔ', 'ɔ':'ʌoɤɔ', 'ʌ':'ʌoɔɤ'}"
      ],
      "metadata": {
        "id": "6PaxYHKEEWuk"
      },
      "id": "6PaxYHKEEWuk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# НАХОЖДЕНИЕ ЗАРИФМОВАННЫХ СТРОК\n",
        "\n",
        "strings = defaultdict(list) \n",
        "# strings = {параграф:[номер_стоки, последний_гласный, \n",
        "#                      последний_слог, последнее слово]}\n",
        "\n",
        "\n",
        "line_keys = song_meta_lyrics[1].keys()\n",
        "\n",
        "for lk in line_keys:\n",
        "    punct = ' ,.\\\"\\'[]()!?-%:;'\n",
        "    last_word = song_meta_lyrics[1][lk][1].split(' ')[-1].strip(punct).lower()\n",
        "    lat_letters = 'qwertyuioplkjhgfdsazxcvbnm'\n",
        "    if len(last_word) != 0:\n",
        "        if last_word[0].lower() in lat_letters:\n",
        "            last_syllable, last_vowel = ender(eti.convert(last_word).strip('*'))\n",
        "        elif last_word[0] in hangul:\n",
        "            last_syllable, last_vowel = ender(\n",
        "                rom_to_ipa(Romanizer(last_word).romanize()))\n",
        "        else:\n",
        "            last_syllable = ''\n",
        "            last_vowel = ''\n",
        "      \n",
        "    par = lk.split('-')[0]\n",
        "    l = lk.split('-')[1]\n",
        "\n",
        "    strings[par].append([l, last_vowel, last_syllable, last_word])\n",
        "\n",
        "\n",
        "rhymes = defaultdict(list) # РИФМЫ\n",
        "possible_rhymes = defaultdict(list) # ВОЗМОЖНЫЕ РИФМЫ\n",
        "\n",
        "for par_i in strings.keys():\n",
        "    paragraph = strings[par_i]\n",
        "    for i in range(0, len(paragraph)):\n",
        "        for j in range(0, len(paragraph)):\n",
        "            if j != i and paragraph[i][1] != '' and paragraph[j][1] != '':\n",
        "                # точные рифмы\n",
        "                if paragraph[j][1] == paragraph[i][1]:\n",
        "                    rhymes[par_i+'-'+str(paragraph[i][0])].append(paragraph[j][3])\n",
        "                # возможные рифмы\n",
        "                if len(paragraph[i][2]) == 1: \n",
        "                    if paragraph[j][2] in rhymed_vowels[paragraph[i][2]]:\n",
        "                        possible_rhymes[par_i+'-'+str(paragraph[i][0])].append(paragraph[j][3])\n",
        "        "
      ],
      "metadata": {
        "id": "Xe42dJzlttJM"
      },
      "id": "Xe42dJzlttJM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Количество слогов и определение языка"
      ],
      "metadata": {
        "id": "Ifc0mrbSD29X"
      },
      "id": "Ifc0mrbSD29X"
    },
    {
      "cell_type": "code",
      "source": [
        "def syll_lang(line, hangul):\n",
        "    ko = 0\n",
        "    en = 0\n",
        "\n",
        "    syllable_length = 0\n",
        "    words = line.split(' ')\n",
        "    \n",
        "    en_letters = 'qwertyuioplkjhgfdsazxcvbnm'\n",
        "\n",
        "    for word in words:\n",
        "        word = word.strip(' ,.\\\"\\'[]()!?-%:;')\n",
        "        if len(word) > 0:\n",
        "            if word[0].lower() in en_letters:\n",
        "                syllable_length += eti.syllable_count(word)\n",
        "                en = 1\n",
        "            elif word[0] in hangul:\n",
        "                # в корейском слоговое письмо\n",
        "                syllable_length += len(word)\n",
        "                ko = 1\n",
        "\n",
        "    if ko == 0 and en == 0:\n",
        "        lang = 3\n",
        "    if ko == 1 and en == 0:\n",
        "        lang = 0\n",
        "    if ko == 0 and en == 1:\n",
        "        lang = 1\n",
        "    if ko == 1 and en == 1:\n",
        "        lang = 4\n",
        "\n",
        "    return syllable_length, lang"
      ],
      "metadata": {
        "id": "ItnNJ-nrFbuP"
      },
      "id": "ItnNJ-nrFbuP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Запись в JSON"
      ],
      "metadata": {
        "id": "6BOiv4QZq3XD"
      },
      "id": "6BOiv4QZq3XD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e992d7f",
      "metadata": {
        "id": "0e992d7f"
      },
      "outputs": [],
      "source": [
        "meta = song_meta_lyrics[0]\n",
        "lyrics = song_meta_lyrics[1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lyrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRloCcIt0bZZ",
        "outputId": "60096fd6-ad37-4409-e94c-a29b27dd3dbb"
      },
      "id": "LRloCcIt0bZZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0-1': ['Почему изучаешь меня', '왜 자꾸 날 연구해'], '0-2': ['Если ты не Эйнштейн?', '아인슈타인도 아니고'], '0-3': ['Почему ты высматриваешь углы?', '왜 그렇게 각을 재'], '0-4': ['Это не конусы и синусы', 'sin, cos도 아니고'], '0-5': ['Тянешь и толкаешь', '밀고 당기는 게'], '0-6': ['Это уже не мой стиль', '내 스타일은 더 아니고'], '0-7': ['Если ты собираешься узнать', '알아보다 말 거면'], '0-8': ['Держись от меня подальше', '눈에 밟히지나 마 좀 제발'], '1-1': ['Ты много думаешь, это проблема', '넌 생각이 많아 문제야 문제'], '1-2': ['Ты пытаешься залезть в мою голову', '머릿속만 들여다보면 뭐 해'], '1-3': ['Твой ответ слишком долго ждать', '각 잴 시간에 답 낼 시간에'], '1-4': ['Лучше сделай шаг', 'Better make a move'], '2-1': ['Любовь - это не наука', \"Love ain't a science\"], '2-2': ['Не нужна лицензия', \"Don't need no license\"], '2-3': ['Ты много думаешь, это минус - я волнуюсь', '머리 싸매고 고민할수록 Minus'], '3-1': ['Не пытайся быть гением', \"Don't try to be a genius\"], '3-2': ['Почему ты такой серьезный?', 'Why so serious?'], '3-3': ['Следуй за своим сердцем', '맘이 가는 대로 Wooah'], '3-4': ['Мое сердце говорит мне, что ты чего-то ждешь', '맘이 시킨 대로 What u, what u waiting for?'], '4-1': ['И, что ты узнал', '그래 뭘 알아냈어?'], '4-2': ['Обо мне сейчас?', '그동안 나에 대해'], '4-3': ['Какая следующая тема?', '다음 과목은 뭐야?'], '4-4': ['Какой же следующий урок?', \"So what's the next class, then?\"], '4-5': ['Я буду учиться, но это закончится неудачей', '백날 연구해봤자 이런 식이면 Failure'], '4-6': ['Разум постоянно изменяется', '분 단위로 바뀌어대는'], '4-7': ['Ты его никогда не поймешь', '내 맘은 못 풀어낼걸'], '5-1': ['Ты много думаешь, это проблема', '넌 생각이 많아 문제야 문제'], '5-2': ['Ты пытаешься залезть в мою голову', '머릿속만 들여다보면 뭐 해'], '5-3': ['Твой ответ слишком долго ждать', '각 잴 시간에 답 낼 시간에'], '5-4': ['Лучше сделай шаг', 'Better make a move'], '6-1': ['Любовь - это не наука', \"Love ain't a science\"], '6-2': ['Не нужна лицензия', \"Don't need no license\"], '6-3': ['Ты много думаешь, это минус - я волнуюсь', '머리 싸매고 고민할수록 Minus'], '7-1': ['Не пытайся быть гением', \"Don't try to be a genius\"], '7-2': ['Почему ты такой серьезный?', 'Why so serious?'], '7-3': ['Следуй за своим сердцем', '맘이 가는 대로 Wooah'], '7-4': ['Мое сердце говорит мне, что ты чего-то ждешь', '맘이 시킨 대로 What u, what u waiting for?'], '8-1': ['Ты влюблен в меня', 'You got a crush on me'], '8-2': ['Ты влюбишься в меня', \"You're gonna fall for me\"], '8-3': ['Теория не поможет, если речь идет о любви', \"사랑 앞에서 이론이 무슨 소용, It's all useless, uh-huh\"], '9-1': ['Более, чем гений Эйнштейн', '이론 빠삭한 Genius 아인슈타인'], '9-2': ['Похож на любопытного Франкенштейна', '보단 불도저 Curious 프랑켄슈타인'], '9-3': ['Я неуклюжая, зато увлекательная', '처럼 돌진해 서툰데 멋지네'], '9-4': ['Не думай, просто поспеши', '거침없이, 세게 Rush'], '9-5': ['Влюбился в меня', 'Got a crush on me'], '10-1': ['Это смешно, потому что ответа нет', '답이 없어 재미있는 걸 넌 왜 몰라'], '10-2': ['Это интересно, потому что ответа нет', '답을 몰라 설레었던 걸 넌 왜 몰라'], '10-3': ['Одной частички не хватает', '나사 하나 빠진 것처럼 사랑하자'], '10-4': ['Я знаю только одно - как будто стала дураком', '딱 하나만 아는 바보 된 것처럼'], '11-1': ['Любовь - это не наука', \"Love ain't a science, uhm-uhm\"], '11-2': ['Не нужна лицензия', 'Need no license, uhm-uhm'], '11-3': ['Исследование обо мне', \"연구해 About me 'bout me\"], '11-4': ['Достаточно, ты знаешь обо мне', \"충분히 You know 'bout me\"], '11-5': ['Любовь - это не наука', \"Love ain't a science, uhm-uhm\"], '11-6': ['Не нужна лицензия', 'Need no license, uhm-uhm'], '11-7': ['Мое сердце говорит мне, что ты чего-то ждешь', '말했잖아 What u, what u, what u waiting for?'], '12-1': ['Любовь - это не наука', \"Love ain't a science\"], '12-2': ['Не нужна лицензия', \"Don't need no license\"], '12-3': ['Ты много думаешь, это минус - я волнуюсь', '머리 싸매고 고민할수록 Minus'], '13-1': ['Не пытайся быть гением', \"Don't try to be a genius\"], '13-2': ['Почему ты такой серьезный?', 'Why so serious?'], '13-3': ['Следуй за своим сердцем', '맘이 가는 대로 Wooah'], '13-4': ['Мое сердце говорит мне, что ты чего-то ждешь', '맘이 시킨 대로 What u, what u waiting for?']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# КООРДИНИРОВАНИЕ ВСЕХ ФУНКЦИЙ\n",
        "processed_korean = []\n",
        "processed_russian = []\n",
        "\n",
        "for lk in lyrics.keys():\n",
        "    para = lk.split('-')[0]\n",
        "    string = lk.split('-')[1]\n",
        "    para_id = int(para)*1000 + int(string)\n",
        "\n",
        "    # корейский\n",
        "    kor_words = tag_ana(lyrics[lk][1], ld, hd)\n",
        "    syll_length, lang = syll_lang(lyrics[lk][1], hangul)\n",
        "    \n",
        "    rhymed = ''\n",
        "    for rh in rhymes[lk]:\n",
        "        rhymed += rh + ', '\n",
        "\n",
        "    pos_rhymed = ''\n",
        "    for prhm in possible_rhymes[lk]:\n",
        "        if prhm not in rhymes[lk]:\n",
        "            pos_rhymed += prhm + ', '\n",
        "    \n",
        "    for line in strings[para]:\n",
        "        if line[0] == string:\n",
        "            last_word = line[3]\n",
        "            last_vowel = line[2]\n",
        "\n",
        "    kor_sent_meta = {'possibly_rhymed_with':pos_rhymed.strip(', '),\n",
        "                     'rhymed_with':rhymed.strip(', '),\n",
        "                     'last_word':last_word,\n",
        "                     'last_vowel':last_vowel,\n",
        "                     'length_in_syllables':syll_length}\n",
        "    # выравнивание\n",
        "    kor_alignment = {'off_start':0,\n",
        "                     'off_end':len(lyrics[lk][1])-1,\n",
        "                     'para_id':para_id}\n",
        "    \n",
        "    kor_sent = {'text':lyrics[lk][1],\n",
        "                'words':kor_words,\n",
        "                'lang':lang,\n",
        "                'meta':kor_sent_meta,\n",
        "                'para_alignment':kor_alignment}\n",
        "    \n",
        "    processed_korean.append(kor_sent)\n",
        "\n",
        "    # русский\n",
        "    rus_sent = rus_tagger(lyrics[lk][0], {'para_id':para_id})\n",
        "    processed_russian.append(rus_sent)\n",
        "\n",
        "\n",
        "processed_korean.extend(processed_russian)\n",
        "final = {'meta':meta, 'sentences':processed_korean}"
      ],
      "metadata": {
        "id": "sGMkqVwQpYD1"
      },
      "id": "sGMkqVwQpYD1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ЗАПИСЬ В КОНЕЧНЫЙ ФАЙЛ\n",
        "with open('Processed ' + file_name, 'w', encoding='utf-8') as out_file:\n",
        "    json.dump(final, out_file, ensure_ascii=False, indent=3)"
      ],
      "metadata": {
        "id": "jw-kvjsH4Yhx"
      },
      "id": "jw-kvjsH4Yhx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Всякая ерунда"
      ],
      "metadata": {
        "id": "SalyawIaLDQs"
      },
      "id": "SalyawIaLDQs"
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(tag_ana(lyrics['4-5'][1], ld, hd))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN8SA8ap8dZa",
        "outputId": "2d80df76-e634-4c7b-8425-967410829cdc"
      },
      "id": "WN8SA8ap8dZa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'ana': {'lang': 1, 'lex': 'You', 'pos': 'PRO'},\n",
            "  'next_word': 1,\n",
            "  'off_end': 2,\n",
            "  'off_start': 0,\n",
            "  'sentence_index': 0,\n",
            "  'sentence_index_neg': 4,\n",
            "  'wf': 'You',\n",
            "  'wtype': 'word'},\n",
            " {'ana': {'lang': 1, 'lex': 'lead', 'pos': 'S, sg'},\n",
            "  'next_word': 2,\n",
            "  'off_end': 8,\n",
            "  'off_start': 4,\n",
            "  'sentence_index': 1,\n",
            "  'sentence_index_neg': 3,\n",
            "  'wf': 'lead',\n",
            "  'wtype': 'word'},\n",
            " {'ana': {'lang': 1, 'lex': 'we', 'pos': 'PRO'},\n",
            "  'next_word': 3,\n",
            "  'off_end': 11,\n",
            "  'off_start': 10,\n",
            "  'sentence_index': 2,\n",
            "  'sentence_index_neg': 2,\n",
            "  'wf': 'we',\n",
            "  'wtype': 'word'},\n",
            " {'ana': {'lang': 1, 'lex': 'follow', 'pos': 'V'},\n",
            "  'off_end': 18,\n",
            "  'off_start': 13,\n",
            "  'sentence_index': 3,\n",
            "  'sentence_index_neg': 1,\n",
            "  'wf': 'follow',\n",
            "  'wtype': 'word'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(rus_tagger(lyrics['0-2'][0], 'alignment here'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm_n21XZXlKC",
        "outputId": "7cb9f40e-2577-448f-fe77-6f2ee343e55a"
      },
      "id": "hm_n21XZXlKC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'lang': 2,\n",
            " 'meta': {'ending': '',\n",
            "          'last_vowel': '',\n",
            "          'last_word': '',\n",
            "          'length_in_syllables': 0,\n",
            "          'possibly_rhymed_with': '',\n",
            "          'rhymed_with': ''},\n",
            " 'para_alignment': 'alignment here',\n",
            " 'text': 'Соблюдай все прописанные правила',\n",
            " 'words': [{'ana': [{'lex': 'соблюдать', 'pos': 'V'}],\n",
            "            'next_word': 1,\n",
            "            'off_end': 7,\n",
            "            'off_start': 0,\n",
            "            'sentence_index': 0,\n",
            "            'sentence_index_neg': 5,\n",
            "            'wf': 'Соблюдай',\n",
            "            'wtype': 'word'},\n",
            "           {'ana': [{'lex': 'весь', 'pos': 'APRO'}],\n",
            "            'next_word': 2,\n",
            "            'off_end': 11,\n",
            "            'off_start': 9,\n",
            "            'sentence_index': 1,\n",
            "            'sentence_index_neg': 4,\n",
            "            'wf': 'все',\n",
            "            'wtype': 'word'},\n",
            "           {'ana': [{'lex': 'прописывать', 'pos': 'V'}],\n",
            "            'next_word': 3,\n",
            "            'off_end': 23,\n",
            "            'off_start': 13,\n",
            "            'sentence_index': 2,\n",
            "            'sentence_index_neg': 3,\n",
            "            'wf': 'прописанные',\n",
            "            'wtype': 'word'},\n",
            "           {'ana': [{'lex': 'правило', 'pos': 'S'}],\n",
            "            'next_word': 4,\n",
            "            'off_end': 31,\n",
            "            'off_start': 25,\n",
            "            'sentence_index': 3,\n",
            "            'sentence_index_neg': 2,\n",
            "            'wf': 'правила',\n",
            "            'wtype': 'word'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Запись в XML"
      ],
      "metadata": {
        "id": "M5P9sN-K6g9b"
      },
      "id": "M5P9sN-K6g9b"
    },
    {
      "cell_type": "code",
      "source": [
        "print(meta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ED_jH7lfShvk",
        "outputId": "461cbc8c-f4ab-4f8e-bb4f-6264c4554b29"
      },
      "id": "ED_jH7lfShvk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'original_song_date': '17/05/2021', 'translation_date': '17/05/2021', 'translator': 'SimplyStar', 'artist': 'aespa (에스파)', 'song': 'Next Level', 'album': 'Next Level'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xml_page = ET.Element('html')\n",
        "head = ET.SubElement(xml_page, 'head')\n",
        "\n",
        "for ml in meta.keys():\n",
        "    meta_xml = ET.SubElement(head, 'meta')\n",
        "    meta_xml.attrib['name'] = ml\n",
        "    meta_xml.attrib['content'] = meta[ml]\n",
        "    \n",
        "ET.dump(xml_page)"
      ],
      "metadata": {
        "id": "-27FIfAt6kxH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "959edf6c-9724-4884-87eb-cbbbd999611e"
      },
      "id": "-27FIfAt6kxH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<html><head><meta content=\"17/05/2021\" name=\"original_song_date\" /><meta content=\"17/05/2021\" name=\"translation_date\" /><meta content=\"SimplyStar\" name=\"translator\" /><meta content=\"aespa (에스파)\" name=\"artist\" /><meta content=\"Next Level\" name=\"song\" /><meta content=\"Next Level\" name=\"album\" /></head></html>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "body = ET.SubElement(xml_page, 'body')\n",
        "\n",
        "for line_key in lyrics.keys():\n",
        "    nkrl_tags, done_line = tag_ana(lyrics[line_key][1])\n",
        "    print(nkrl_tags)\n",
        "    print(done_line)\n",
        "    print('\\n')\n",
        "\n",
        "    # para - это ведь одна строка, не абзац?\n",
        "    para = ET.SubElement(body, 'para')\n",
        "    para.attrib['id'] = line_key\n",
        "\n",
        "    se1 = ET.SubElement(para, 'se')\n",
        "    se1.text = lyrics[line_key][0]\n",
        "    se1.attrib['lang'] = 'ru'\n",
        "    # тут можно так 2 языка указать?\n",
        "    # можно сделать более подробный анализ: фраза только на \n",
        "    # корейском, только на английском или ko-en\n",
        "    se2 = ET.SubElement(para, 'se')\n",
        "    se2.attrib['lang'] = 'ko-en'\n",
        "    se2.text = lyrics[line_key][1]\n",
        "    se3 = ET.SubElement(para, 'se')\n",
        "    se3.attrib['lang'] = 'ko-en'\n",
        "\n",
        "    # запись уровня слов\n",
        "    \n",
        "    # запись уровня морфем\n",
        "    for token in done_line:\n",
        "        w = ET.SubElement(se3, 'w')\n",
        "        w.text = token['lex']\n",
        "        ana = ET.SubElement(w, 'ana')\n",
        "        ana.attrib['lang'] = token['lang']\n",
        "        ana.attrib['lex'] = token['lex']\n",
        "        ana.attrib['gr'] = token['gr']\n",
        "        ana.attrib['transcr'] = token['transcr']"
      ],
      "metadata": {
        "id": "b7FL6YCjSpKg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "fd3eb259-4c6a-4a5e-b811-de78f545fbde"
      },
      "id": "b7FL6YCjSpKg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-cfd90eef1ecc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline_key\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlyrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mnkrl_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_ana\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlyrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mline_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnkrl_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-37bd621ca10d>\u001b[0m in \u001b[0;36mtag_ana\u001b[0;34m(org)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdone_tok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# просто обработка kkma или nltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mdone_toks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone_tok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mncrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone_tok\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# теги нкря\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mnkrl_token_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnkrl_token_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone_toks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-74dce753fb9c>\u001b[0m in \u001b[0;36mncrl\u001b[0;34m(fw, ms)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mmors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lex'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lang'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'en'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfull_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_ncrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mfinal_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-244b24eebc6d>\u001b[0m in \u001b[0;36men_ncrl\u001b[0;34m(ems)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'\\''\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_tag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'true_tag' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ET.dump(body)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FseBsrl5bi2m",
        "outputId": "9ac9e39a-d7fe-4418-bda3-b7fe7d5ed556"
      },
      "id": "FseBsrl5bi2m",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<body><para id=\"0-1\"><se lang=\"ru\">Я на следующем уровне, да</se><se lang=\"ko-en\">I'm on the Next Level Yeah</se><se lang=\"ko-en\"><w>I<ana gr=\"PRP\" lang=\"en\" lex=\"I\" transcr=\"I\" /></w><w>'<ana gr=\"punct\" lang=\"none\" lex=\"'\" transcr=\"'\" /></w><w>m<ana gr=\"NN\" lang=\"en\" lex=\"m\" transcr=\"m\" /></w><w>on<ana gr=\"NN\" lang=\"en\" lex=\"on\" transcr=\"on\" /></w><w>the<ana gr=\"NN\" lang=\"en\" lex=\"the\" transcr=\"the\" /></w><w>Next<ana gr=\"NNP\" lang=\"en\" lex=\"Next\" transcr=\"Next\" /></w><w>Level<ana gr=\"NNP\" lang=\"en\" lex=\"Level\" transcr=\"Level\" /></w><w>Yeah<ana gr=\"NNP\" lang=\"en\" lex=\"Yeah\" transcr=\"Yeah\" /></w></se></para id=\"0-1\"><para id=\"0-2\"><se lang=\"ru\">Соблюдай все прописанные правила</se><se lang=\"ko-en\">절대적 룰을 지켜</se><se lang=\"ko-en\"><w>절대적<ana gr=\"NNG\" lang=\"ko\" lex=\"절대적\" transcr=\"jeoldaejeok\" /></w><w>룰<ana gr=\"NNG\" lang=\"ko\" lex=\"룰\" transcr=\"rul\" /></w><w>을<ana gr=\"JKO\" lang=\"ko\" lex=\"을\" transcr=\"eul\" /></w><w>지키<ana gr=\"VV\" lang=\"ko\" lex=\"지키\" transcr=\"jiki\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w></se></para id=\"0-2\"><para id=\"0-3\"><se lang=\"ru\">Не отпускай мою руку</se><se lang=\"ko-en\">내 손을 놓지 말아</se><se lang=\"ko-en\"><w>내<ana gr=\"NP\" lang=\"ko\" lex=\"내\" transcr=\"nae\" /></w><w>손<ana gr=\"NNG\" lang=\"ko\" lex=\"손\" transcr=\"son\" /></w><w>을<ana gr=\"JKO\" lang=\"ko\" lex=\"을\" transcr=\"eul\" /></w><w>놓<ana gr=\"VV\" lang=\"ko\" lex=\"놓\" transcr=\"no\" /></w><w>지<ana gr=\"ECD\" lang=\"ko\" lex=\"지\" transcr=\"ji\" /></w><w>말<ana gr=\"VV\" lang=\"ko\" lex=\"말\" transcr=\"mal\" /></w><w>아<ana gr=\"ECD\" lang=\"ko\" lex=\"아\" transcr=\"a\" /></w></se></para id=\"0-3\"><para id=\"0-4\"><se lang=\"ru\">Потому что это единственное оружие</se><se lang=\"ko-en\">결속은 나의 무기</se><se lang=\"ko-en\"><w>결속<ana gr=\"NNG\" lang=\"ko\" lex=\"결속\" transcr=\"gyeolsok\" /></w><w>은<ana gr=\"JX\" lang=\"ko\" lex=\"은\" transcr=\"eun\" /></w><w>나의<ana gr=\"NNG\" lang=\"ko\" lex=\"나의\" transcr=\"naui\" /></w><w>무기<ana gr=\"NNG\" lang=\"ko\" lex=\"무기\" transcr=\"mugi\" /></w></se></para id=\"0-4\"><para id=\"0-5\"><se lang=\"ru\">Я иду в пустыню</se><se lang=\"ko-en\">광야로 걸어가</se><se lang=\"ko-en\"><w>광야<ana gr=\"NNG\" lang=\"ko\" lex=\"광야\" transcr=\"gwangya\" /></w><w>로<ana gr=\"JKM\" lang=\"ko\" lex=\"로\" transcr=\"ro\" /></w><w>걸어가<ana gr=\"VV\" lang=\"ko\" lex=\"걸어가\" transcr=\"georeoga\" /></w></se></para id=\"0-5\"><para id=\"0-6\"><se lang=\"ru\">Я знаю, где ты родился</se><se lang=\"ko-en\">알아 네 Home ground</se><se lang=\"ko-en\"><w>알<ana gr=\"VV\" lang=\"ko\" lex=\"알\" transcr=\"al\" /></w><w>아<ana gr=\"ECD\" lang=\"ko\" lex=\"아\" transcr=\"a\" /></w><w>네<ana gr=\"MDN\" lang=\"ko\" lex=\"네\" transcr=\"ne\" /></w><w>Home<ana gr=\"NNP\" lang=\"en\" lex=\"Home\" transcr=\"Home\" /></w><w>ground<ana gr=\"NN\" lang=\"en\" lex=\"ground\" transcr=\"ground\" /></w></se></para id=\"0-6\"><para id=\"0-7\"><se lang=\"ru\">Нужно противостоять угрозе</se><se lang=\"ko-en\">위협에 맞서서</se><se lang=\"ko-en\"><w>위협<ana gr=\"NNG\" lang=\"ko\" lex=\"위협\" transcr=\"wihyeop\" /></w><w>에<ana gr=\"JKM\" lang=\"ko\" lex=\"에\" transcr=\"e\" /></w><w>맞서<ana gr=\"VV\" lang=\"ko\" lex=\"맞서\" transcr=\"matseo\" /></w><w>서<ana gr=\"ECD\" lang=\"ko\" lex=\"서\" transcr=\"seo\" /></w></se></para id=\"0-7\"><para id=\"0-8\"><se lang=\"ru\">Противостоять, противостоять</se><se lang=\"ko-en\">제껴라 제껴라 제껴라</se><se lang=\"ko-en\"><w>제끼<ana gr=\"VV\" lang=\"ko\" lex=\"제끼\" transcr=\"jekki\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w><w>라<ana gr=\"NNG\" lang=\"ko\" lex=\"라\" transcr=\"ra\" /></w><w>제끼<ana gr=\"VV\" lang=\"ko\" lex=\"제끼\" transcr=\"jekki\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w><w>라<ana gr=\"NNG\" lang=\"ko\" lex=\"라\" transcr=\"ra\" /></w><w>제끼<ana gr=\"VV\" lang=\"ko\" lex=\"제끼\" transcr=\"jekki\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w><w>라<ana gr=\"NNG\" lang=\"ko\" lex=\"라\" transcr=\"ra\" /></w></se></para id=\"0-8\"><para id=\"1-1\"><se lang=\"ru\">Впереди нас долгое путешествие</se><se lang=\"ko-en\">상상도 못한 Black out</se><se lang=\"ko-en\"><w>상상<ana gr=\"NNG\" lang=\"ko\" lex=\"상상\" transcr=\"sangsang\" /></w><w>도<ana gr=\"JX\" lang=\"ko\" lex=\"도\" transcr=\"do\" /></w><w>못하<ana gr=\"VX\" lang=\"ko\" lex=\"못하\" transcr=\"motha\" /></w><w>ㄴ<ana gr=\"ETD\" lang=\"ko\" lex=\"ㄴ\" transcr=\"ㄴ\" /></w><w>Black<ana gr=\"NNP\" lang=\"en\" lex=\"Black\" transcr=\"Black\" /></w><w>out<ana gr=\"JJ\" lang=\"en\" lex=\"out\" transcr=\"out\" /></w></se></para id=\"1-1\"><para id=\"1-2\"><se lang=\"ru\">Искушение глубокое и глубокое</se><se lang=\"ko-en\">유혹은 깊고 진해</se><se lang=\"ko-en\"><w>유혹<ana gr=\"NNG\" lang=\"ko\" lex=\"유혹\" transcr=\"yuhok\" /></w><w>은<ana gr=\"JX\" lang=\"ko\" lex=\"은\" transcr=\"eun\" /></w><w>깊<ana gr=\"VA\" lang=\"ko\" lex=\"깊\" transcr=\"gip\" /></w><w>고<ana gr=\"ECE\" lang=\"ko\" lex=\"고\" transcr=\"go\" /></w><w>진해<ana gr=\"NNG\" lang=\"ko\" lex=\"진해\" transcr=\"jinhae\" /></w></se></para id=\"1-2\"><para id=\"1-3\"><se lang=\"ru\">(Слишком жарко, слишком жарко)</se><se lang=\"ko-en\">(Too hot too hot)</se><se lang=\"ko-en\"><w>(<ana gr=\"punct\" lang=\"none\" lex=\"(\" transcr=\"(\" /></w><w>Too<ana gr=\"NNP\" lang=\"en\" lex=\"Too\" transcr=\"Too\" /></w><w>hot<ana gr=\"NN\" lang=\"en\" lex=\"hot\" transcr=\"hot\" /></w><w>too<ana gr=\"NN\" lang=\"en\" lex=\"too\" transcr=\"too\" /></w><w>hot<ana gr=\"NN\" lang=\"en\" lex=\"hot\" transcr=\"hot\" /></w><w>)<ana gr=\"punct\" lang=\"none\" lex=\")\" transcr=\")\" /></w></se></para id=\"1-3\"><para id=\"1-4\"><se lang=\"ru\">Я пошла против правил - отпустила твою руку</se><se lang=\"ko-en\">맞잡은 손을 놓쳐</se><se lang=\"ko-en\"><w>맞잡<ana gr=\"VV\" lang=\"ko\" lex=\"맞잡\" transcr=\"matjap\" /></w><w>은<ana gr=\"ETD\" lang=\"ko\" lex=\"은\" transcr=\"eun\" /></w><w>손<ana gr=\"NNG\" lang=\"ko\" lex=\"손\" transcr=\"son\" /></w><w>을<ana gr=\"JKO\" lang=\"ko\" lex=\"을\" transcr=\"eul\" /></w><w>놓치<ana gr=\"VV\" lang=\"ko\" lex=\"놓치\" transcr=\"nochi\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w></se></para id=\"1-4\"><para id=\"1-5\"><se lang=\"ru\">Но это не означает, что сдамся</se><se lang=\"ko-en\">난 절대 포기 못해</se><se lang=\"ko-en\"><w>낳<ana gr=\"VV\" lang=\"ko\" lex=\"낳\" transcr=\"na\" /></w><w>ㄴ<ana gr=\"ETD\" lang=\"ko\" lex=\"ㄴ\" transcr=\"ㄴ\" /></w><w>절대<ana gr=\"NNG\" lang=\"ko\" lex=\"절대\" transcr=\"jeoldae\" /></w><w>포기<ana gr=\"NNG\" lang=\"ko\" lex=\"포기\" transcr=\"pogi\" /></w><w>못하<ana gr=\"VX\" lang=\"ko\" lex=\"못하\" transcr=\"motha\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w></se></para id=\"1-5\"><para id=\"2-1\"><se lang=\"ru\">Я на следующем уровне</se><se lang=\"ko-en\">I'm on the Next Level</se><se lang=\"ko-en\"><w>I<ana gr=\"PRP\" lang=\"en\" lex=\"I\" transcr=\"I\" /></w><w>'<ana gr=\"punct\" lang=\"none\" lex=\"'\" transcr=\"'\" /></w><w>m<ana gr=\"NN\" lang=\"en\" lex=\"m\" transcr=\"m\" /></w><w>on<ana gr=\"NN\" lang=\"en\" lex=\"on\" transcr=\"on\" /></w><w>the<ana gr=\"NN\" lang=\"en\" lex=\"the\" transcr=\"the\" /></w><w>Next<ana gr=\"NNP\" lang=\"en\" lex=\"Next\" transcr=\"Next\" /></w><w>Level<ana gr=\"NNP\" lang=\"en\" lex=\"Level\" transcr=\"Level\" /></w></se></para id=\"2-1\"><para id=\"2-2\"><se lang=\"ru\">Я открываю следующую дверь</se><se lang=\"ko-en\">저 너머의 문을 열어</se><se lang=\"ko-en\"><w>저<ana gr=\"MDT\" lang=\"ko\" lex=\"저\" transcr=\"jeo\" /></w><w>너머<ana gr=\"NNG\" lang=\"ko\" lex=\"너머\" transcr=\"neomeo\" /></w><w>의<ana gr=\"JKG\" lang=\"ko\" lex=\"의\" transcr=\"ui\" /></w><w>문<ana gr=\"NNG\" lang=\"ko\" lex=\"문\" transcr=\"mun\" /></w><w>을<ana gr=\"JKO\" lang=\"ko\" lex=\"을\" transcr=\"eul\" /></w><w>열<ana gr=\"VV\" lang=\"ko\" lex=\"열\" transcr=\"yeol\" /></w><w>어<ana gr=\"ECD\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w></se></para id=\"2-2\"><para id=\"2-3\"><se lang=\"ru\">Следующий уровень</se><se lang=\"ko-en\">Next Level</se><se lang=\"ko-en\"><w>Next<ana gr=\"NNP\" lang=\"en\" lex=\"Next\" transcr=\"Next\" /></w><w>Level<ana gr=\"NNP\" lang=\"en\" lex=\"Level\" transcr=\"Level\" /></w></se></para id=\"2-3\"><para id=\"2-4\"><se lang=\"ru\">Я иду, чтобы уничтожить тебя</se><se lang=\"ko-en\">널 결국엔 내가 부셔</se><se lang=\"ko-en\"><w>넣<ana gr=\"VV\" lang=\"ko\" lex=\"넣\" transcr=\"neo\" /></w><w>ㄹ<ana gr=\"ETD\" lang=\"ko\" lex=\"ㄹ\" transcr=\"ㄹ\" /></w><w>결국<ana gr=\"NNG\" lang=\"ko\" lex=\"결국\" transcr=\"gyeolguk\" /></w><w>에<ana gr=\"JKM\" lang=\"ko\" lex=\"에\" transcr=\"e\" /></w><w>는<ana gr=\"JX\" lang=\"ko\" lex=\"는\" transcr=\"neun\" /></w><w>나<ana gr=\"NP\" lang=\"ko\" lex=\"나\" transcr=\"na\" /></w><w>가<ana gr=\"JKS\" lang=\"ko\" lex=\"가\" transcr=\"ga\" /></w><w>부시<ana gr=\"VV\" lang=\"ko\" lex=\"부시\" transcr=\"busi\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w></se></para id=\"2-4\"><para id=\"2-5\"><se lang=\"ru\">Следующий уровень</se><se lang=\"ko-en\">Next Level</se><se lang=\"ko-en\"><w>Next<ana gr=\"NNP\" lang=\"en\" lex=\"Next\" transcr=\"Next\" /></w><w>Level<ana gr=\"NNP\" lang=\"en\" lex=\"Level\" transcr=\"Level\" /></w></se></para id=\"2-5\"><para id=\"2-6\"><se lang=\"ru\">Пока не дойду до КОСМО</se><se lang=\"ko-en\">KOSMO에 닿을 때까지</se><se lang=\"ko-en\"><w>KOSMO<ana gr=\"NNP\" lang=\"en\" lex=\"KOSMO\" transcr=\"KOSMO\" /></w><w>에<ana gr=\"JKM\" lang=\"ko\" lex=\"에\" transcr=\"e\" /></w><w>닿<ana gr=\"VV\" lang=\"ko\" lex=\"닿\" transcr=\"da\" /></w><w>을<ana gr=\"ETD\" lang=\"ko\" lex=\"을\" transcr=\"eul\" /></w><w>때<ana gr=\"NNG\" lang=\"ko\" lex=\"때\" transcr=\"ttae\" /></w><w>까지<ana gr=\"JX\" lang=\"ko\" lex=\"까지\" transcr=\"kkaji\" /></w></se></para id=\"2-6\"><para id=\"2-7\"><se lang=\"ru\">Следующий уровень</se><se lang=\"ko-en\">Next Level</se><se lang=\"ko-en\"><w>Next<ana gr=\"NNP\" lang=\"en\" lex=\"Next\" transcr=\"Next\" /></w><w>Level<ana gr=\"NNP\" lang=\"en\" lex=\"Level\" transcr=\"Level\" /></w></se></para id=\"2-7\"><para id=\"2-8\"><se lang=\"ru\">Я побежу, побежу, побежу</se><se lang=\"ko-en\">제껴라 제껴라 제껴라</se><se lang=\"ko-en\"><w>제끼<ana gr=\"VV\" lang=\"ko\" lex=\"제끼\" transcr=\"jekki\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w><w>라<ana gr=\"NNG\" lang=\"ko\" lex=\"라\" transcr=\"ra\" /></w><w>제끼<ana gr=\"VV\" lang=\"ko\" lex=\"제끼\" transcr=\"jekki\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w><w>라<ana gr=\"NNG\" lang=\"ko\" lex=\"라\" transcr=\"ra\" /></w><w>제끼<ana gr=\"VV\" lang=\"ko\" lex=\"제끼\" transcr=\"jekki\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w><w>라<ana gr=\"NNG\" lang=\"ko\" lex=\"라\" transcr=\"ra\" /></w></se></para id=\"2-8\"><para id=\"3-1\"><se lang=\"ru\">Ла-ла-ла-ла-ла-ла</se><se lang=\"ko-en\">La la la la la la</se><se lang=\"ko-en\"><w>La<ana gr=\"VB\" lang=\"en\" lex=\"La\" transcr=\"La\" /></w><w>la<ana gr=\"NN\" lang=\"en\" lex=\"la\" transcr=\"la\" /></w><w>la<ana gr=\"NN\" lang=\"en\" lex=\"la\" transcr=\"la\" /></w><w>la<ana gr=\"NN\" lang=\"en\" lex=\"la\" transcr=\"la\" /></w><w>la<ana gr=\"NN\" lang=\"en\" lex=\"la\" transcr=\"la\" /></w><w>la<ana gr=\"NN\" lang=\"en\" lex=\"la\" transcr=\"la\" /></w></se></para id=\"3-1\"><para id=\"3-2\"><se lang=\"ru\">Ла-ла-ла-ла-ла-ла</se><se lang=\"ko-en\">La la la la la la</se><se lang=\"ko-en\"><w>La<ana gr=\"VB\" lang=\"en\" lex=\"La\" transcr=\"La\" /></w><w>la<ana gr=\"NN\" lang=\"en\" lex=\"la\" transcr=\"la\" /></w><w>la<ana gr=\"NN\" lang=\"en\" lex=\"la\" transcr=\"la\" /></w><w>la<ana gr=\"NN\" lang=\"en\" lex=\"la\" transcr=\"la\" /></w><w>la<ana gr=\"NN\" lang=\"en\" lex=\"la\" transcr=\"la\" /></w><w>la<ana gr=\"NN\" lang=\"en\" lex=\"la\" transcr=\"la\" /></w></se></para id=\"3-2\"><para id=\"3-3\"><se lang=\"ru\">Ла-ла-ла-ла-ла-ла</se><se lang=\"ko-en\">La la la la la la</se><se lang=\"ko-en\"><w>La<ana gr=\"VB\" lang=\"en\" lex=\"La\" transcr=\"La\" /></w><w>la<ana gr=\"NN\" lang=\"en\" lex=\"la\" transcr=\"la\" /></w><w>la<ana gr=\"NN\" lang=\"en\" lex=\"la\" transcr=\"la\" /></w><w>la<ana gr=\"NN\" lang=\"en\" lex=\"la\" transcr=\"la\" /></w><w>la<ana gr=\"NN\" lang=\"en\" lex=\"la\" transcr=\"la\" /></w><w>la<ana gr=\"NN\" lang=\"en\" lex=\"la\" transcr=\"la\" /></w></se></para id=\"3-3\"><para id=\"3-4\"><se lang=\"ru\">Ла-ла-ла-ла-ла</se><se lang=\"ko-en\">La la la la la</se><se lang=\"ko-en\"><w>La<ana gr=\"VB\" lang=\"en\" lex=\"La\" transcr=\"La\" /></w><w>la<ana gr=\"NN\" lang=\"en\" lex=\"la\" transcr=\"la\" /></w><w>la<ana gr=\"NN\" lang=\"en\" lex=\"la\" transcr=\"la\" /></w><w>la<ana gr=\"NN\" lang=\"en\" lex=\"la\" transcr=\"la\" /></w><w>la<ana gr=\"NN\" lang=\"en\" lex=\"la\" transcr=\"la\" /></w></se></para id=\"3-4\"><para id=\"4-1\"><se lang=\"ru\">Я вижу NU EVO</se><se lang=\"ko-en\">I see the NU EVO.</se><se lang=\"ko-en\"><w>I<ana gr=\"PRP\" lang=\"en\" lex=\"I\" transcr=\"I\" /></w><w>see<ana gr=\"NN\" lang=\"en\" lex=\"see\" transcr=\"see\" /></w><w>the<ana gr=\"NN\" lang=\"en\" lex=\"the\" transcr=\"the\" /></w><w>NU<ana gr=\"NNP\" lang=\"en\" lex=\"NU\" transcr=\"NU\" /></w><w>EVO<ana gr=\"NNP\" lang=\"en\" lex=\"EVO\" transcr=\"EVO\" /></w><w>.<ana gr=\"punct\" lang=\"none\" lex=\".\" transcr=\".\" /></w></se></para id=\"4-1\"><para id=\"4-2\"><se lang=\"ru\">Где врожденные страдания и печаль</se><se lang=\"ko-en\">적대적인 고난과 슬픔은</se><se lang=\"ko-en\"><w>적대적<ana gr=\"NNG\" lang=\"ko\" lex=\"적대적\" transcr=\"jeokdaejeok\" /></w><w>이<ana gr=\"VCP\" lang=\"ko\" lex=\"이\" transcr=\"i\" /></w><w>ㄴ<ana gr=\"ETD\" lang=\"ko\" lex=\"ㄴ\" transcr=\"ㄴ\" /></w><w>고난<ana gr=\"NNG\" lang=\"ko\" lex=\"고난\" transcr=\"gonan\" /></w><w>과<ana gr=\"JC\" lang=\"ko\" lex=\"과\" transcr=\"gwa\" /></w><w>슬픔<ana gr=\"NNG\" lang=\"ko\" lex=\"슬픔\" transcr=\"seulpeum\" /></w><w>은<ana gr=\"JX\" lang=\"ko\" lex=\"은\" transcr=\"eun\" /></w></se></para id=\"4-2\"><para id=\"4-3\"><se lang=\"ru\">Я заставлю тебя развиваться дальше</se><se lang=\"ko-en\">널 더 Popping 진화시켜</se><se lang=\"ko-en\"><w>넣<ana gr=\"VV\" lang=\"ko\" lex=\"넣\" transcr=\"neo\" /></w><w>ㄹ<ana gr=\"ETD\" lang=\"ko\" lex=\"ㄹ\" transcr=\"ㄹ\" /></w><w>더<ana gr=\"MAG\" lang=\"ko\" lex=\"더\" transcr=\"deo\" /></w><w>Popping<ana gr=\"NNP\" lang=\"en\" lex=\"Popping\" transcr=\"Popping\" /></w><w>진화<ana gr=\"NNG\" lang=\"ko\" lex=\"진화\" transcr=\"jinhwa\" /></w><w>시키<ana gr=\"XSV\" lang=\"ko\" lex=\"시키\" transcr=\"siki\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w></se></para id=\"4-3\"><para id=\"4-4\"><se lang=\"ru\">Это мой остров, это мой остров</se><se lang=\"ko-en\">That's my naevis It's my naevis</se><se lang=\"ko-en\"><w>That<ana gr=\"NNP\" lang=\"en\" lex=\"That\" transcr=\"That\" /></w><w>'<ana gr=\"punct\" lang=\"none\" lex=\"'\" transcr=\"'\" /></w><w>s<ana gr=\"NN\" lang=\"en\" lex=\"s\" transcr=\"s\" /></w><w>my<ana gr=\"NN\" lang=\"en\" lex=\"my\" transcr=\"my\" /></w><w>naevis<ana gr=\"RB\" lang=\"en\" lex=\"naevis\" transcr=\"naevis\" /></w><w>It<ana gr=\"PRP\" lang=\"en\" lex=\"It\" transcr=\"It\" /></w><w>'<ana gr=\"punct\" lang=\"none\" lex=\"'\" transcr=\"'\" /></w><w>s<ana gr=\"NN\" lang=\"en\" lex=\"s\" transcr=\"s\" /></w><w>my<ana gr=\"NN\" lang=\"en\" lex=\"my\" transcr=\"my\" /></w><w>naevis<ana gr=\"RB\" lang=\"en\" lex=\"naevis\" transcr=\"naevis\" /></w></se></para id=\"4-4\"><para id=\"4-5\"><se lang=\"ru\">Ты ведешь, я следую</se><se lang=\"ko-en\">You lead, we follow</se><se lang=\"ko-en\"><w>You<ana gr=\"NNP\" lang=\"en\" lex=\"You\" transcr=\"You\" /></w><w>lead<ana gr=\"NN\" lang=\"en\" lex=\"lead\" transcr=\"lead\" /></w><w>,<ana gr=\"punct\" lang=\"none\" lex=\",\" transcr=\",\" /></w><w>we<ana gr=\"NN\" lang=\"en\" lex=\"we\" transcr=\"we\" /></w><w>follow<ana gr=\"JJ\" lang=\"en\" lex=\"follow\" transcr=\"follow\" /></w></se></para id=\"4-5\"><para id=\"4-6\"><se lang=\"ru\">Я узнаю твои чувства</se><se lang=\"ko-en\">감정들을 배운 다음</se><se lang=\"ko-en\"><w>감정<ana gr=\"NNG\" lang=\"ko\" lex=\"감정\" transcr=\"gamjeong\" /></w><w>들<ana gr=\"XSN\" lang=\"ko\" lex=\"들\" transcr=\"deul\" /></w><w>을<ana gr=\"JKO\" lang=\"ko\" lex=\"을\" transcr=\"eul\" /></w><w>배우<ana gr=\"VV\" lang=\"ko\" lex=\"배우\" transcr=\"baeu\" /></w><w>ㄴ<ana gr=\"ETD\" lang=\"ko\" lex=\"ㄴ\" transcr=\"ㄴ\" /></w><w>다음<ana gr=\"NNG\" lang=\"ko\" lex=\"다음\" transcr=\"daeum\" /></w></se></para id=\"4-6\"><para id=\"4-7\"><se lang=\"ru\">Смотри на меня, пока я выхожу</se><se lang=\"ko-en\">Watch me while I make it out</se><se lang=\"ko-en\"><w>Watch<ana gr=\"WRB\" lang=\"en\" lex=\"Watch\" transcr=\"Watch\" /></w><w>me<ana gr=\"NN\" lang=\"en\" lex=\"me\" transcr=\"me\" /></w><w>while<ana gr=\"NN\" lang=\"en\" lex=\"while\" transcr=\"while\" /></w><w>I<ana gr=\"PRP\" lang=\"en\" lex=\"I\" transcr=\"I\" /></w><w>make<ana gr=\"NN\" lang=\"en\" lex=\"make\" transcr=\"make\" /></w><w>it<ana gr=\"NN\" lang=\"en\" lex=\"it\" transcr=\"it\" /></w><w>out<ana gr=\"JJ\" lang=\"en\" lex=\"out\" transcr=\"out\" /></w></se></para id=\"4-7\"><para id=\"5-1\"><se lang=\"ru\">Смотри на меня, пока я работаю над этим</se><se lang=\"ko-en\">Watch me while I work it out</se><se lang=\"ko-en\"><w>Watch<ana gr=\"WRB\" lang=\"en\" lex=\"Watch\" transcr=\"Watch\" /></w><w>me<ana gr=\"NN\" lang=\"en\" lex=\"me\" transcr=\"me\" /></w><w>while<ana gr=\"NN\" lang=\"en\" lex=\"while\" transcr=\"while\" /></w><w>I<ana gr=\"PRP\" lang=\"en\" lex=\"I\" transcr=\"I\" /></w><w>work<ana gr=\"NN\" lang=\"en\" lex=\"work\" transcr=\"work\" /></w><w>it<ana gr=\"NN\" lang=\"en\" lex=\"it\" transcr=\"it\" /></w><w>out<ana gr=\"JJ\" lang=\"en\" lex=\"out\" transcr=\"out\" /></w></se></para id=\"5-1\"><para id=\"5-2\"><se lang=\"ru\">Смотри на меня, пока я выхожу</se><se lang=\"ko-en\">Watch me while I make it out</se><se lang=\"ko-en\"><w>Watch<ana gr=\"WRB\" lang=\"en\" lex=\"Watch\" transcr=\"Watch\" /></w><w>me<ana gr=\"NN\" lang=\"en\" lex=\"me\" transcr=\"me\" /></w><w>while<ana gr=\"NN\" lang=\"en\" lex=\"while\" transcr=\"while\" /></w><w>I<ana gr=\"PRP\" lang=\"en\" lex=\"I\" transcr=\"I\" /></w><w>make<ana gr=\"NN\" lang=\"en\" lex=\"make\" transcr=\"make\" /></w><w>it<ana gr=\"NN\" lang=\"en\" lex=\"it\" transcr=\"it\" /></w><w>out<ana gr=\"JJ\" lang=\"en\" lex=\"out\" transcr=\"out\" /></w></se></para id=\"5-2\"><para id=\"5-3\"><se lang=\"ru\">Смотри на меня, пока я над этим работаю</se><se lang=\"ko-en\">Watch me while I work it out</se><se lang=\"ko-en\"><w>Watch<ana gr=\"WRB\" lang=\"en\" lex=\"Watch\" transcr=\"Watch\" /></w><w>me<ana gr=\"NN\" lang=\"en\" lex=\"me\" transcr=\"me\" /></w><w>while<ana gr=\"NN\" lang=\"en\" lex=\"while\" transcr=\"while\" /></w><w>I<ana gr=\"PRP\" lang=\"en\" lex=\"I\" transcr=\"I\" /></w><w>work<ana gr=\"NN\" lang=\"en\" lex=\"work\" transcr=\"work\" /></w><w>it<ana gr=\"NN\" lang=\"en\" lex=\"it\" transcr=\"it\" /></w><w>out<ana gr=\"JJ\" lang=\"en\" lex=\"out\" transcr=\"out\" /></w></se></para id=\"5-3\"><para id=\"5-4\"><se lang=\"ru\">Работаю, работаю, работаю над этим</se><se lang=\"ko-en\">Work it work it work it out</se><se lang=\"ko-en\"><w>Work<ana gr=\"NNP\" lang=\"en\" lex=\"Work\" transcr=\"Work\" /></w><w>it<ana gr=\"NN\" lang=\"en\" lex=\"it\" transcr=\"it\" /></w><w>work<ana gr=\"NN\" lang=\"en\" lex=\"work\" transcr=\"work\" /></w><w>it<ana gr=\"NN\" lang=\"en\" lex=\"it\" transcr=\"it\" /></w><w>work<ana gr=\"NN\" lang=\"en\" lex=\"work\" transcr=\"work\" /></w><w>it<ana gr=\"NN\" lang=\"en\" lex=\"it\" transcr=\"it\" /></w><w>out<ana gr=\"JJ\" lang=\"en\" lex=\"out\" transcr=\"out\" /></w></se></para id=\"5-4\"><para id=\"6-1\"><se lang=\"ru\">Я не могу справиться с отчаянием</se><se lang=\"ko-en\">감당할 수 없는 절망도</se><se lang=\"ko-en\"><w>감당<ana gr=\"NNG\" lang=\"ko\" lex=\"감당\" transcr=\"gamdang\" /></w><w>하<ana gr=\"XSV\" lang=\"ko\" lex=\"하\" transcr=\"ha\" /></w><w>ㄹ<ana gr=\"ETD\" lang=\"ko\" lex=\"ㄹ\" transcr=\"ㄹ\" /></w><w>수<ana gr=\"NNB\" lang=\"ko\" lex=\"수\" transcr=\"su\" /></w><w>없<ana gr=\"VA\" lang=\"ko\" lex=\"없\" transcr=\"eop\" /></w><w>는<ana gr=\"ETD\" lang=\"ko\" lex=\"는\" transcr=\"neun\" /></w><w>절망<ana gr=\"NNG\" lang=\"ko\" lex=\"절망\" transcr=\"jeolmang\" /></w><w>도<ana gr=\"JX\" lang=\"ko\" lex=\"도\" transcr=\"do\" /></w></se></para id=\"6-1\"><para id=\"6-2\"><se lang=\"ru\">Ты не сможешь сломить мою веру</se><se lang=\"ko-en\">내 믿음을 깨지 못해</se><se lang=\"ko-en\"><w>내<ana gr=\"NP\" lang=\"ko\" lex=\"내\" transcr=\"nae\" /></w><w>믿음<ana gr=\"NNG\" lang=\"ko\" lex=\"믿음\" transcr=\"mideum\" /></w><w>을<ana gr=\"JKO\" lang=\"ko\" lex=\"을\" transcr=\"eul\" /></w><w>깨<ana gr=\"VV\" lang=\"ko\" lex=\"깨\" transcr=\"kkae\" /></w><w>지<ana gr=\"ECD\" lang=\"ko\" lex=\"지\" transcr=\"ji\" /></w><w>못하<ana gr=\"VX\" lang=\"ko\" lex=\"못하\" transcr=\"motha\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w></se></para id=\"6-2\"><para id=\"6-3\"><se lang=\"ru\">Даже если я столкнусь с более болезненным испытанием</se><se lang=\"ko-en\">더 아픈 시련을 맞아도</se><se lang=\"ko-en\"><w>더<ana gr=\"MAG\" lang=\"ko\" lex=\"더\" transcr=\"deo\" /></w><w>아프<ana gr=\"VA\" lang=\"ko\" lex=\"아프\" transcr=\"apeu\" /></w><w>ㄴ<ana gr=\"ETD\" lang=\"ko\" lex=\"ㄴ\" transcr=\"ㄴ\" /></w><w>시련<ana gr=\"NNG\" lang=\"ko\" lex=\"시련\" transcr=\"siryeon\" /></w><w>을<ana gr=\"JKO\" lang=\"ko\" lex=\"을\" transcr=\"eul\" /></w><w>맞<ana gr=\"VV\" lang=\"ko\" lex=\"맞\" transcr=\"mat\" /></w><w>아도<ana gr=\"ECD\" lang=\"ko\" lex=\"아도\" transcr=\"ado\" /></w></se></para id=\"6-3\"><para id=\"6-4\"><se lang=\"ru\">Я не отпущу твою руку</se><se lang=\"ko-en\">난 잡은 손을 놓지 않을게 Oh</se><se lang=\"ko-en\"><w>난<ana gr=\"NNG\" lang=\"ko\" lex=\"난\" transcr=\"nan\" /></w><w>잡<ana gr=\"VV\" lang=\"ko\" lex=\"잡\" transcr=\"jap\" /></w><w>은<ana gr=\"ETD\" lang=\"ko\" lex=\"은\" transcr=\"eun\" /></w><w>손<ana gr=\"NNG\" lang=\"ko\" lex=\"손\" transcr=\"son\" /></w><w>을<ana gr=\"JKO\" lang=\"ko\" lex=\"을\" transcr=\"eul\" /></w><w>놓<ana gr=\"VV\" lang=\"ko\" lex=\"놓\" transcr=\"no\" /></w><w>지<ana gr=\"ECD\" lang=\"ko\" lex=\"지\" transcr=\"ji\" /></w><w>않<ana gr=\"VXV\" lang=\"ko\" lex=\"않\" transcr=\"transcription_error\" /></w><w>을게<ana gr=\"EFN\" lang=\"ko\" lex=\"을게\" transcr=\"eulge\" /></w><w>Oh<ana gr=\"NNP\" lang=\"en\" lex=\"Oh\" transcr=\"Oh\" /></w></se></para id=\"6-4\"><para id=\"7-1\"><se lang=\"ru\">Никогда не оглядывайся назад</se><se lang=\"ko-en\">절대로 뒤를 돌아보지 말아</se><se lang=\"ko-en\"><w>절대로<ana gr=\"MAG\" lang=\"ko\" lex=\"절대로\" transcr=\"jeoldaero\" /></w><w>뒤<ana gr=\"NNG\" lang=\"ko\" lex=\"뒤\" transcr=\"dwi\" /></w><w>를<ana gr=\"JKO\" lang=\"ko\" lex=\"를\" transcr=\"reul\" /></w><w>돌아보<ana gr=\"VV\" lang=\"ko\" lex=\"돌아보\" transcr=\"dorabo\" /></w><w>지<ana gr=\"ECD\" lang=\"ko\" lex=\"지\" transcr=\"ji\" /></w><w>말<ana gr=\"VV\" lang=\"ko\" lex=\"말\" transcr=\"mal\" /></w><w>아<ana gr=\"ECD\" lang=\"ko\" lex=\"아\" transcr=\"a\" /></w></se></para id=\"7-1\"><para id=\"7-2\"><se lang=\"ru\">Не нужно идти в пустыню</se><se lang=\"ko-en\">광야의 것 탐내지 말아</se><se lang=\"ko-en\"><w>광야<ana gr=\"NNG\" lang=\"ko\" lex=\"광야\" transcr=\"gwangya\" /></w><w>의<ana gr=\"JKG\" lang=\"ko\" lex=\"의\" transcr=\"ui\" /></w><w>것<ana gr=\"NNB\" lang=\"ko\" lex=\"것\" transcr=\"geot\" /></w><w>탐내<ana gr=\"VV\" lang=\"ko\" lex=\"탐내\" transcr=\"tamnae\" /></w><w>지<ana gr=\"ECD\" lang=\"ko\" lex=\"지\" transcr=\"ji\" /></w><w>말<ana gr=\"VV\" lang=\"ko\" lex=\"말\" transcr=\"mal\" /></w><w>아<ana gr=\"ECD\" lang=\"ko\" lex=\"아\" transcr=\"a\" /></w></se></para id=\"7-2\"><para id=\"7-3\"><se lang=\"ru\">Когда обещание нарушено</se><se lang=\"ko-en\">약속이 깨지면</se><se lang=\"ko-en\"><w>약속<ana gr=\"NNG\" lang=\"ko\" lex=\"약속\" transcr=\"yaksok\" /></w><w>이<ana gr=\"JKS\" lang=\"ko\" lex=\"이\" transcr=\"i\" /></w><w>깨지<ana gr=\"VV\" lang=\"ko\" lex=\"깨지\" transcr=\"kkaeji\" /></w><w>면<ana gr=\"ECE\" lang=\"ko\" lex=\"면\" transcr=\"myeon\" /></w></se></para id=\"7-3\"><para id=\"7-4\"><se lang=\"ru\">Все выходят из-под контроля</se><se lang=\"ko-en\">모두 걷잡을 수 없게 돼</se><se lang=\"ko-en\"><w>모두<ana gr=\"MAG\" lang=\"ko\" lex=\"모두\" transcr=\"modu\" /></w><w>걷잡<ana gr=\"VV\" lang=\"ko\" lex=\"걷잡\" transcr=\"geotjap\" /></w><w>을<ana gr=\"ETD\" lang=\"ko\" lex=\"을\" transcr=\"eul\" /></w><w>수<ana gr=\"NNB\" lang=\"ko\" lex=\"수\" transcr=\"su\" /></w><w>없<ana gr=\"VA\" lang=\"ko\" lex=\"없\" transcr=\"eop\" /></w><w>게<ana gr=\"ECD\" lang=\"ko\" lex=\"게\" transcr=\"ge\" /></w><w>되<ana gr=\"VA\" lang=\"ko\" lex=\"되\" transcr=\"doe\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w></se></para id=\"7-4\"><para id=\"7-5\"><se lang=\"ru\">Сигнал становится неточным</se><se lang=\"ko-en\">언제부턴가 불안해져 가는 신호</se><se lang=\"ko-en\"><w>언제<ana gr=\"MAG\" lang=\"ko\" lex=\"언제\" transcr=\"eonje\" /></w><w>부<ana gr=\"XPN\" lang=\"ko\" lex=\"부\" transcr=\"bu\" /></w><w>턴<ana gr=\"NNG\" lang=\"ko\" lex=\"턴\" transcr=\"teon\" /></w><w>가<ana gr=\"XSN\" lang=\"ko\" lex=\"가\" transcr=\"ga\" /></w><w>불안<ana gr=\"NNG\" lang=\"ko\" lex=\"불안\" transcr=\"buran\" /></w><w>해지<ana gr=\"VV\" lang=\"ko\" lex=\"해지\" transcr=\"haeji\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w><w>갈<ana gr=\"VV\" lang=\"ko\" lex=\"갈\" transcr=\"gal\" /></w><w>는<ana gr=\"ETD\" lang=\"ko\" lex=\"는\" transcr=\"neun\" /></w><w>신호<ana gr=\"NNG\" lang=\"ko\" lex=\"신호\" transcr=\"sinho\" /></w></se></para id=\"7-5\"><para id=\"7-6\"><se lang=\"ru\">Я уничтожу тебя в итоге</se><se lang=\"ko-en\">널 파괴하고 말 거야</se><se lang=\"ko-en\"><w>넣<ana gr=\"VV\" lang=\"ko\" lex=\"넣\" transcr=\"neo\" /></w><w>ㄹ<ana gr=\"ETD\" lang=\"ko\" lex=\"ㄹ\" transcr=\"ㄹ\" /></w><w>파괴<ana gr=\"NNG\" lang=\"ko\" lex=\"파괴\" transcr=\"pagoe\" /></w><w>하<ana gr=\"XSV\" lang=\"ko\" lex=\"하\" transcr=\"ha\" /></w><w>고<ana gr=\"ECE\" lang=\"ko\" lex=\"고\" transcr=\"go\" /></w><w>말<ana gr=\"NNG\" lang=\"ko\" lex=\"말\" transcr=\"mal\" /></w><w>그<ana gr=\"VV\" lang=\"ko\" lex=\"그\" transcr=\"geu\" /></w><w>어야<ana gr=\"ECD\" lang=\"ko\" lex=\"어야\" transcr=\"eoya\" /></w></se></para id=\"7-6\"><para id=\"7-7\"><se lang=\"ru\">(Мы этого хотим)</se><se lang=\"ko-en\">(We want it)</se><se lang=\"ko-en\"><w>(<ana gr=\"punct\" lang=\"none\" lex=\"(\" transcr=\"(\" /></w><w>We<ana gr=\"NNP\" lang=\"en\" lex=\"We\" transcr=\"We\" /></w><w>want<ana gr=\"VB\" lang=\"en\" lex=\"want\" transcr=\"want\" /></w><w>it<ana gr=\"NN\" lang=\"en\" lex=\"it\" transcr=\"it\" /></w><w>)<ana gr=\"punct\" lang=\"none\" lex=\")\" transcr=\")\" /></w></se></para id=\"7-7\"><para id=\"7-8\"><se lang=\"ru\">Давай!</se><se lang=\"ko-en\">Come on!</se><se lang=\"ko-en\"><w>Come<ana gr=\"NNP\" lang=\"en\" lex=\"Come\" transcr=\"Come\" /></w><w>on<ana gr=\"NN\" lang=\"en\" lex=\"on\" transcr=\"on\" /></w><w>!<ana gr=\"punct\" lang=\"none\" lex=\"!\" transcr=\"!\" /></w></se></para id=\"7-8\"><para id=\"7-9\"><se lang=\"ru\">Покажи мне дорогу в КОСМО, да</se><se lang=\"ko-en\">Show me the way to KOSMO Yeah</se><se lang=\"ko-en\"><w>Show<ana gr=\"NNP\" lang=\"en\" lex=\"Show\" transcr=\"Show\" /></w><w>me<ana gr=\"NN\" lang=\"en\" lex=\"me\" transcr=\"me\" /></w><w>the<ana gr=\"NN\" lang=\"en\" lex=\"the\" transcr=\"the\" /></w><w>way<ana gr=\"VB\" lang=\"en\" lex=\"way\" transcr=\"way\" /></w><w>to<ana gr=\"NN\" lang=\"en\" lex=\"to\" transcr=\"to\" /></w><w>KOSMO<ana gr=\"NNP\" lang=\"en\" lex=\"KOSMO\" transcr=\"KOSMO\" /></w><w>Yeah<ana gr=\"NNP\" lang=\"en\" lex=\"Yeah\" transcr=\"Yeah\" /></w></se></para id=\"7-9\"><para id=\"8-1\"><se lang=\"ru\">Квест галлюцинаций, созданный Черной Мамбой</se><se lang=\"ko-en\">Black Mamba가 만들어낸 환각 퀘스트</se><se lang=\"ko-en\"><w>Black<ana gr=\"NNP\" lang=\"en\" lex=\"Black\" transcr=\"Black\" /></w><w>Mamba<ana gr=\"NNP\" lang=\"en\" lex=\"Mamba\" transcr=\"Mamba\" /></w><w>가<ana gr=\"JKS\" lang=\"ko\" lex=\"가\" transcr=\"ga\" /></w><w>만들<ana gr=\"VV\" lang=\"ko\" lex=\"만들\" transcr=\"mandeul\" /></w><w>어<ana gr=\"ECD\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w><w>내<ana gr=\"VXV\" lang=\"ko\" lex=\"내\" transcr=\"nae\" /></w><w>ㄴ<ana gr=\"ETD\" lang=\"ko\" lex=\"ㄴ\" transcr=\"ㄴ\" /></w><w>환각<ana gr=\"NNG\" lang=\"ko\" lex=\"환각\" transcr=\"hwangak\" /></w><w>퀘스<ana gr=\"UN\" lang=\"ko\" lex=\"퀘스\" transcr=\"kweseu\" /></w><w>트<ana gr=\"VV\" lang=\"ko\" lex=\"트\" transcr=\"teu\" /></w></se></para id=\"8-1\"><para id=\"8-2\"><se lang=\"ru\">Эспа, они хотят нас отделить, да</se><se lang=\"ko-en\">aespa, ae를 분리시켜놓길 원해 그래</se><se lang=\"ko-en\"><w>aespa<ana gr=\"DT\" lang=\"en\" lex=\"aespa\" transcr=\"aespa\" /></w><w>,<ana gr=\"punct\" lang=\"none\" lex=\",\" transcr=\",\" /></w><w>ae<ana gr=\"DT\" lang=\"en\" lex=\"ae\" transcr=\"ae\" /></w><w>를<ana gr=\"JKO\" lang=\"ko\" lex=\"를\" transcr=\"reul\" /></w><w>분리<ana gr=\"NNG\" lang=\"ko\" lex=\"분리\" transcr=\"bunri\" /></w><w>시키<ana gr=\"XSV\" lang=\"ko\" lex=\"시키\" transcr=\"siki\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w><w>놓<ana gr=\"VXV\" lang=\"ko\" lex=\"놓\" transcr=\"no\" /></w><w>기<ana gr=\"ETN\" lang=\"ko\" lex=\"기\" transcr=\"gi\" /></w><w>를<ana gr=\"JKO\" lang=\"ko\" lex=\"를\" transcr=\"reul\" /></w><w>원하<ana gr=\"VV\" lang=\"ko\" lex=\"원하\" transcr=\"wonha\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w><w>그래<ana gr=\"JX\" lang=\"ko\" lex=\"그래\" transcr=\"geurae\" /></w></se></para id=\"8-2\"><para id=\"8-3\"><se lang=\"ru\">Теряюсь в центре, теряю равновесие и голос</se><se lang=\"ko-en\">중심을 잃고 목소리도 잃고 비난받고</se><se lang=\"ko-en\"><w>중심<ana gr=\"NNG\" lang=\"ko\" lex=\"중심\" transcr=\"jungsim\" /></w><w>을<ana gr=\"JKO\" lang=\"ko\" lex=\"을\" transcr=\"eul\" /></w><w>잃<ana gr=\"VV\" lang=\"ko\" lex=\"잃\" transcr=\"transcription_error\" /></w><w>고<ana gr=\"ECE\" lang=\"ko\" lex=\"고\" transcr=\"go\" /></w><w>목<ana gr=\"NNG\" lang=\"ko\" lex=\"목\" transcr=\"mok\" /></w><w>소리<ana gr=\"NNG\" lang=\"ko\" lex=\"소리\" transcr=\"sori\" /></w><w>도<ana gr=\"JX\" lang=\"ko\" lex=\"도\" transcr=\"do\" /></w><w>잃<ana gr=\"VV\" lang=\"ko\" lex=\"잃\" transcr=\"transcription_error\" /></w><w>고<ana gr=\"ECE\" lang=\"ko\" lex=\"고\" transcr=\"go\" /></w><w>비난<ana gr=\"NNG\" lang=\"ko\" lex=\"비난\" transcr=\"binan\" /></w><w>받<ana gr=\"VV\" lang=\"ko\" lex=\"받\" transcr=\"bat\" /></w><w>고<ana gr=\"ECE\" lang=\"ko\" lex=\"고\" transcr=\"go\" /></w></se></para id=\"8-3\"><para id=\"8-4\"><se lang=\"ru\">В иллюзии критики людей</se><se lang=\"ko-en\">사람들과 멀어지는 착각 속에</se><se lang=\"ko-en\"><w>사람<ana gr=\"NNG\" lang=\"ko\" lex=\"사람\" transcr=\"saram\" /></w><w>들<ana gr=\"XSN\" lang=\"ko\" lex=\"들\" transcr=\"deul\" /></w><w>과<ana gr=\"JKO\" lang=\"ko\" lex=\"과\" transcr=\"gwa\" /></w><w>멀<ana gr=\"VV\" lang=\"ko\" lex=\"멀\" transcr=\"meol\" /></w><w>어<ana gr=\"ECD\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w><w>지<ana gr=\"VXV\" lang=\"ko\" lex=\"지\" transcr=\"ji\" /></w><w>는<ana gr=\"ETD\" lang=\"ko\" lex=\"는\" transcr=\"neun\" /></w><w>착각<ana gr=\"NNG\" lang=\"ko\" lex=\"착각\" transcr=\"chakgak\" /></w><w>속<ana gr=\"NNG\" lang=\"ko\" lex=\"속\" transcr=\"sok\" /></w><w>에<ana gr=\"JKM\" lang=\"ko\" lex=\"에\" transcr=\"e\" /></w></se></para id=\"8-4\"><para id=\"8-5\"><se lang=\"ru\">В этом месте, зови нас эй, эй</se><se lang=\"ko-en\">naevis우리 ae, ae들을 불러봐</se><se lang=\"ko-en\"><w>naevis<ana gr=\"RB\" lang=\"en\" lex=\"naevis\" transcr=\"naevis\" /></w><w>우리<ana gr=\"NP\" lang=\"ko\" lex=\"우리\" transcr=\"uri\" /></w><w>ae<ana gr=\"DT\" lang=\"en\" lex=\"ae\" transcr=\"ae\" /></w><w>,<ana gr=\"punct\" lang=\"none\" lex=\",\" transcr=\",\" /></w><w>ae<ana gr=\"DT\" lang=\"en\" lex=\"ae\" transcr=\"ae\" /></w><w>들<ana gr=\"NNG\" lang=\"ko\" lex=\"들\" transcr=\"deul\" /></w><w>을<ana gr=\"JKO\" lang=\"ko\" lex=\"을\" transcr=\"eul\" /></w><w>불르<ana gr=\"VV\" lang=\"ko\" lex=\"불르\" transcr=\"bulreu\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w><w>보<ana gr=\"VV\" lang=\"ko\" lex=\"보\" transcr=\"bo\" /></w><w>아<ana gr=\"ECS\" lang=\"ko\" lex=\"아\" transcr=\"a\" /></w></se></para id=\"8-5\"><para id=\"8-6\"><se lang=\"ru\">Открылся следующий уровень aespa «P.O.S»</se><se lang=\"ko-en\">aespa의 Next Level “P.O.S”를 열어봐</se><se lang=\"ko-en\"><w>aespa<ana gr=\"DT\" lang=\"en\" lex=\"aespa\" transcr=\"aespa\" /></w><w>의<ana gr=\"JKG\" lang=\"ko\" lex=\"의\" transcr=\"ui\" /></w><w>Next<ana gr=\"NNP\" lang=\"en\" lex=\"Next\" transcr=\"Next\" /></w><w>Level<ana gr=\"NNP\" lang=\"en\" lex=\"Level\" transcr=\"Level\" /></w><w>“<ana gr=\"punct\" lang=\"none\" lex=\"“\" transcr=\"“\" /></w><w>P<ana gr=\"NN\" lang=\"en\" lex=\"P\" transcr=\"P\" /></w><w>.<ana gr=\"punct\" lang=\"none\" lex=\".\" transcr=\".\" /></w><w>O<ana gr=\"NN\" lang=\"en\" lex=\"O\" transcr=\"O\" /></w><w>.<ana gr=\"punct\" lang=\"none\" lex=\".\" transcr=\".\" /></w><w>S<ana gr=\"NN\" lang=\"en\" lex=\"S\" transcr=\"S\" /></w><w>”<ana gr=\"punct\" lang=\"none\" lex=\"”\" transcr=\"”\" /></w><w>를<ana gr=\"JKO\" lang=\"ko\" lex=\"를\" transcr=\"reul\" /></w><w>열<ana gr=\"VV\" lang=\"ko\" lex=\"열\" transcr=\"yeol\" /></w><w>어<ana gr=\"ECD\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w><w>보<ana gr=\"VV\" lang=\"ko\" lex=\"보\" transcr=\"bo\" /></w><w>아<ana gr=\"ECS\" lang=\"ko\" lex=\"아\" transcr=\"a\" /></w></se></para id=\"8-6\"><para id=\"8-7\"><se lang=\"ru\">Это настоящий мир, не сон</se><se lang=\"ko-en\">이건 REAL WORLD 깨어났어</se><se lang=\"ko-en\"><w>이<ana gr=\"VCP\" lang=\"ko\" lex=\"이\" transcr=\"i\" /></w><w>건<ana gr=\"ECE\" lang=\"ko\" lex=\"건\" transcr=\"geon\" /></w><w>REAL<ana gr=\"NNP\" lang=\"en\" lex=\"REAL\" transcr=\"REAL\" /></w><w>WORLD<ana gr=\"NNP\" lang=\"en\" lex=\"WORLD\" transcr=\"WORLD\" /></w><w>깨어나<ana gr=\"VV\" lang=\"ko\" lex=\"깨어나\" transcr=\"kkaeeona\" /></w><w>었<ana gr=\"EPT\" lang=\"ko\" lex=\"었\" transcr=\"eot\" /></w><w>어<ana gr=\"EFN\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w></se></para id=\"8-7\"><para id=\"8-8\"><se lang=\"ru\">Мы против злодея</se><se lang=\"ko-en\">We against the villain</se><se lang=\"ko-en\"><w>We<ana gr=\"NNP\" lang=\"en\" lex=\"We\" transcr=\"We\" /></w><w>against<ana gr=\"DT\" lang=\"en\" lex=\"against\" transcr=\"against\" /></w><w>the<ana gr=\"NN\" lang=\"en\" lex=\"the\" transcr=\"the\" /></w><w>villain<ana gr=\"NN\" lang=\"en\" lex=\"villain\" transcr=\"villain\" /></w></se></para id=\"8-8\"><para id=\"8-9\"><se lang=\"ru\">Какое имя?</se><se lang=\"ko-en\">What's the name?</se><se lang=\"ko-en\"><w>What<ana gr=\"NNP\" lang=\"en\" lex=\"What\" transcr=\"What\" /></w><w>'<ana gr=\"punct\" lang=\"none\" lex=\"'\" transcr=\"'\" /></w><w>s<ana gr=\"NN\" lang=\"en\" lex=\"s\" transcr=\"s\" /></w><w>the<ana gr=\"NN\" lang=\"en\" lex=\"the\" transcr=\"the\" /></w><w>name<ana gr=\"RB\" lang=\"en\" lex=\"name\" transcr=\"name\" /></w><w>?<ana gr=\"punct\" lang=\"none\" lex=\"?\" transcr=\"?\" /></w></se></para id=\"8-9\"><para id=\"8-10\"><se lang=\"ru\">Черная мамба</se><se lang=\"ko-en\">Black Mamba</se><se lang=\"ko-en\"><w>Black<ana gr=\"NNP\" lang=\"en\" lex=\"Black\" transcr=\"Black\" /></w><w>Mamba<ana gr=\"NNP\" lang=\"en\" lex=\"Mamba\" transcr=\"Mamba\" /></w></se></para id=\"8-10\"><para id=\"9-1\"><se lang=\"ru\">В конце концов я открываю дверь</se><se lang=\"ko-en\">결국 난 문을 열어</se><se lang=\"ko-en\"><w>결국<ana gr=\"NNG\" lang=\"ko\" lex=\"결국\" transcr=\"gyeolguk\" /></w><w>난<ana gr=\"NNG\" lang=\"ko\" lex=\"난\" transcr=\"nan\" /></w><w>문<ana gr=\"NNG\" lang=\"ko\" lex=\"문\" transcr=\"mun\" /></w><w>을<ana gr=\"JKO\" lang=\"ko\" lex=\"을\" transcr=\"eul\" /></w><w>열<ana gr=\"VV\" lang=\"ko\" lex=\"열\" transcr=\"yeol\" /></w><w>어<ana gr=\"ECD\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w></se></para id=\"9-1\"><para id=\"9-2\"><se lang=\"ru\">Этот свет, как огонь</se><se lang=\"ko-en\">그 빛은 네겐 Fire</se><se lang=\"ko-en\"><w>그<ana gr=\"MDT\" lang=\"ko\" lex=\"그\" transcr=\"geu\" /></w><w>빛<ana gr=\"NNG\" lang=\"ko\" lex=\"빛\" transcr=\"bit\" /></w><w>은<ana gr=\"JX\" lang=\"ko\" lex=\"은\" transcr=\"eun\" /></w><w>네<ana gr=\"MDN\" lang=\"ko\" lex=\"네\" transcr=\"ne\" /></w><w>겐<ana gr=\"UN\" lang=\"ko\" lex=\"겐\" transcr=\"gen\" /></w><w>Fire<ana gr=\"NNP\" lang=\"en\" lex=\"Fire\" transcr=\"Fire\" /></w></se></para id=\"9-2\"><para id=\"9-3\"><se lang=\"ru\">(Слишком жарко, слишком жарко)</se><se lang=\"ko-en\">(Too hot too hot)</se><se lang=\"ko-en\"><w>(<ana gr=\"punct\" lang=\"none\" lex=\"(\" transcr=\"(\" /></w><w>Too<ana gr=\"NNP\" lang=\"en\" lex=\"Too\" transcr=\"Too\" /></w><w>hot<ana gr=\"NN\" lang=\"en\" lex=\"hot\" transcr=\"hot\" /></w><w>too<ana gr=\"NN\" lang=\"en\" lex=\"too\" transcr=\"too\" /></w><w>hot<ana gr=\"NN\" lang=\"en\" lex=\"hot\" transcr=\"hot\" /></w><w>)<ana gr=\"punct\" lang=\"none\" lex=\")\" transcr=\")\" /></w></se></para id=\"9-3\"><para id=\"9-4\"><se lang=\"ru\">Мне любопытно, я схожу с ума</se><se lang=\"ko-en\">난 궁금해 미치겠어</se><se lang=\"ko-en\"><w>나<ana gr=\"NP\" lang=\"ko\" lex=\"나\" transcr=\"na\" /></w><w>는<ana gr=\"JX\" lang=\"ko\" lex=\"는\" transcr=\"neun\" /></w><w>궁금하<ana gr=\"VA\" lang=\"ko\" lex=\"궁금하\" transcr=\"gunggeumha\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w><w>미치<ana gr=\"VV\" lang=\"ko\" lex=\"미치\" transcr=\"michi\" /></w><w>겠<ana gr=\"EPT\" lang=\"ko\" lex=\"겠\" transcr=\"get\" /></w><w>어<ana gr=\"EFN\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w></se></para id=\"9-4\"><para id=\"9-5\"><se lang=\"ru\">Следующая история, чтобы разворачиваться</se><se lang=\"ko-en\">이다음에 펼칠 Story</se><se lang=\"ko-en\"><w>이다음<ana gr=\"NNG\" lang=\"ko\" lex=\"이다음\" transcr=\"idaeum\" /></w><w>에<ana gr=\"JKM\" lang=\"ko\" lex=\"에\" transcr=\"e\" /></w><w>펼치<ana gr=\"VV\" lang=\"ko\" lex=\"펼치\" transcr=\"pyeolchi\" /></w><w>ㄹ<ana gr=\"ETD\" lang=\"ko\" lex=\"ㄹ\" transcr=\"ㄹ\" /></w><w>Story<ana gr=\"NNP\" lang=\"en\" lex=\"Story\" transcr=\"Story\" /></w></se></para id=\"9-5\"><para id=\"9-6\"><se lang=\"ru\">Хм!</se><se lang=\"ko-en\">Huh!</se><se lang=\"ko-en\"><w>Huh<ana gr=\"NNP\" lang=\"en\" lex=\"Huh\" transcr=\"Huh\" /></w><w>!<ana gr=\"punct\" lang=\"none\" lex=\"!\" transcr=\"!\" /></w></se></para id=\"9-6\"><para id=\"10-1\"><se lang=\"ru\">Я на следующем уровне</se><se lang=\"ko-en\">I'm on the Next Level</se><se lang=\"ko-en\"><w>I<ana gr=\"PRP\" lang=\"en\" lex=\"I\" transcr=\"I\" /></w><w>'<ana gr=\"punct\" lang=\"none\" lex=\"'\" transcr=\"'\" /></w><w>m<ana gr=\"NN\" lang=\"en\" lex=\"m\" transcr=\"m\" /></w><w>on<ana gr=\"NN\" lang=\"en\" lex=\"on\" transcr=\"on\" /></w><w>the<ana gr=\"NN\" lang=\"en\" lex=\"the\" transcr=\"the\" /></w><w>Next<ana gr=\"NNP\" lang=\"en\" lex=\"Next\" transcr=\"Next\" /></w><w>Level<ana gr=\"NNP\" lang=\"en\" lex=\"Level\" transcr=\"Level\" /></w></se></para id=\"10-1\"><para id=\"10-2\"><se lang=\"ru\">Я открываю следующую дверь</se><se lang=\"ko-en\">저 너머의 문을 열어</se><se lang=\"ko-en\"><w>저<ana gr=\"MDT\" lang=\"ko\" lex=\"저\" transcr=\"jeo\" /></w><w>너머<ana gr=\"NNG\" lang=\"ko\" lex=\"너머\" transcr=\"neomeo\" /></w><w>의<ana gr=\"JKG\" lang=\"ko\" lex=\"의\" transcr=\"ui\" /></w><w>문<ana gr=\"NNG\" lang=\"ko\" lex=\"문\" transcr=\"mun\" /></w><w>을<ana gr=\"JKO\" lang=\"ko\" lex=\"을\" transcr=\"eul\" /></w><w>열<ana gr=\"VV\" lang=\"ko\" lex=\"열\" transcr=\"yeol\" /></w><w>어<ana gr=\"ECD\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w></se></para id=\"10-2\"><para id=\"10-3\"><se lang=\"ru\">Следующий уровень</se><se lang=\"ko-en\">Next Level</se><se lang=\"ko-en\"><w>Next<ana gr=\"NNP\" lang=\"en\" lex=\"Next\" transcr=\"Next\" /></w><w>Level<ana gr=\"NNP\" lang=\"en\" lex=\"Level\" transcr=\"Level\" /></w></se></para id=\"10-3\"><para id=\"10-4\"><se lang=\"ru\">Я иду, чтобы уничтожить тебя</se><se lang=\"ko-en\">널 결국엔 내가 부셔</se><se lang=\"ko-en\"><w>넣<ana gr=\"VV\" lang=\"ko\" lex=\"넣\" transcr=\"neo\" /></w><w>ㄹ<ana gr=\"ETD\" lang=\"ko\" lex=\"ㄹ\" transcr=\"ㄹ\" /></w><w>결국<ana gr=\"NNG\" lang=\"ko\" lex=\"결국\" transcr=\"gyeolguk\" /></w><w>에<ana gr=\"JKM\" lang=\"ko\" lex=\"에\" transcr=\"e\" /></w><w>는<ana gr=\"JX\" lang=\"ko\" lex=\"는\" transcr=\"neun\" /></w><w>나<ana gr=\"NP\" lang=\"ko\" lex=\"나\" transcr=\"na\" /></w><w>가<ana gr=\"JKS\" lang=\"ko\" lex=\"가\" transcr=\"ga\" /></w><w>부시<ana gr=\"VV\" lang=\"ko\" lex=\"부시\" transcr=\"busi\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w></se></para id=\"10-4\"><para id=\"10-5\"><se lang=\"ru\">Следующий уровень</se><se lang=\"ko-en\">Next Level</se><se lang=\"ko-en\"><w>Next<ana gr=\"NNP\" lang=\"en\" lex=\"Next\" transcr=\"Next\" /></w><w>Level<ana gr=\"NNP\" lang=\"en\" lex=\"Level\" transcr=\"Level\" /></w></se></para id=\"10-5\"><para id=\"10-6\"><se lang=\"ru\">Пока не дойду до КОСМО</se><se lang=\"ko-en\">KOSMO에 닿을 때까지</se><se lang=\"ko-en\"><w>KOSMO<ana gr=\"NNP\" lang=\"en\" lex=\"KOSMO\" transcr=\"KOSMO\" /></w><w>에<ana gr=\"JKM\" lang=\"ko\" lex=\"에\" transcr=\"e\" /></w><w>닿<ana gr=\"VV\" lang=\"ko\" lex=\"닿\" transcr=\"da\" /></w><w>을<ana gr=\"ETD\" lang=\"ko\" lex=\"을\" transcr=\"eul\" /></w><w>때<ana gr=\"NNG\" lang=\"ko\" lex=\"때\" transcr=\"ttae\" /></w><w>까지<ana gr=\"JX\" lang=\"ko\" lex=\"까지\" transcr=\"kkaji\" /></w></se></para id=\"10-6\"><para id=\"10-7\"><se lang=\"ru\">Следующий уровень</se><se lang=\"ko-en\">Next Level</se><se lang=\"ko-en\"><w>Next<ana gr=\"NNP\" lang=\"en\" lex=\"Next\" transcr=\"Next\" /></w><w>Level<ana gr=\"NNP\" lang=\"en\" lex=\"Level\" transcr=\"Level\" /></w></se></para id=\"10-7\"><para id=\"10-8\"><se lang=\"ru\">Я побежу, побежу, побежу</se><se lang=\"ko-en\">제껴라 제껴라 제껴라</se><se lang=\"ko-en\"><w>제끼<ana gr=\"VV\" lang=\"ko\" lex=\"제끼\" transcr=\"jekki\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w><w>라<ana gr=\"NNG\" lang=\"ko\" lex=\"라\" transcr=\"ra\" /></w><w>제끼<ana gr=\"VV\" lang=\"ko\" lex=\"제끼\" transcr=\"jekki\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w><w>라<ana gr=\"NNG\" lang=\"ko\" lex=\"라\" transcr=\"ra\" /></w><w>제끼<ana gr=\"VV\" lang=\"ko\" lex=\"제끼\" transcr=\"jekki\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w><w>라<ana gr=\"NNG\" lang=\"ko\" lex=\"라\" transcr=\"ra\" /></w></se></para id=\"10-8\"><para id=\"11-1\"><se lang=\"ru\">Я на следующем уровне</se><se lang=\"ko-en\">I'm on the Next Level</se><se lang=\"ko-en\"><w>I<ana gr=\"PRP\" lang=\"en\" lex=\"I\" transcr=\"I\" /></w><w>'<ana gr=\"punct\" lang=\"none\" lex=\"'\" transcr=\"'\" /></w><w>m<ana gr=\"NN\" lang=\"en\" lex=\"m\" transcr=\"m\" /></w><w>on<ana gr=\"NN\" lang=\"en\" lex=\"on\" transcr=\"on\" /></w><w>the<ana gr=\"NN\" lang=\"en\" lex=\"the\" transcr=\"the\" /></w><w>Next<ana gr=\"NNP\" lang=\"en\" lex=\"Next\" transcr=\"Next\" /></w><w>Level<ana gr=\"NNP\" lang=\"en\" lex=\"Level\" transcr=\"Level\" /></w></se></para id=\"11-1\"><para id=\"11-2\"><se lang=\"ru\">Стань сильнее и свободнее</se><se lang=\"ko-en\">더 강해져 자유롭게</se><se lang=\"ko-en\"><w>더<ana gr=\"MAG\" lang=\"ko\" lex=\"더\" transcr=\"deo\" /></w><w>강<ana gr=\"NNG\" lang=\"ko\" lex=\"강\" transcr=\"gang\" /></w><w>해지<ana gr=\"VV\" lang=\"ko\" lex=\"해지\" transcr=\"haeji\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w><w>자유<ana gr=\"NNG\" lang=\"ko\" lex=\"자유\" transcr=\"jayu\" /></w><w>롭<ana gr=\"XSA\" lang=\"ko\" lex=\"롭\" transcr=\"rop\" /></w><w>게<ana gr=\"ECD\" lang=\"ko\" lex=\"게\" transcr=\"ge\" /></w></se></para id=\"11-2\"><para id=\"11-3\"><se lang=\"ru\">Следующий уровень</se><se lang=\"ko-en\">Next Level</se><se lang=\"ko-en\"><w>Next<ana gr=\"NNP\" lang=\"en\" lex=\"Next\" transcr=\"Next\" /></w><w>Level<ana gr=\"NNP\" lang=\"en\" lex=\"Level\" transcr=\"Level\" /></w></se></para id=\"11-3\"><para id=\"11-4\"><se lang=\"ru\">Я не в пустыне</se><se lang=\"ko-en\">난 광야의 내가 아냐</se><se lang=\"ko-en\"><w>낳<ana gr=\"VV\" lang=\"ko\" lex=\"낳\" transcr=\"na\" /></w><w>ㄴ<ana gr=\"ETD\" lang=\"ko\" lex=\"ㄴ\" transcr=\"ㄴ\" /></w><w>광야<ana gr=\"NNG\" lang=\"ko\" lex=\"광야\" transcr=\"gwangya\" /></w><w>의<ana gr=\"JKG\" lang=\"ko\" lex=\"의\" transcr=\"ui\" /></w><w>내가<ana gr=\"NNG\" lang=\"ko\" lex=\"내가\" transcr=\"naega\" /></w><w>아냐<ana gr=\"IC\" lang=\"ko\" lex=\"아냐\" transcr=\"anya\" /></w></se></para id=\"11-4\"><para id=\"11-5\"><se lang=\"ru\">Следующий уровень</se><se lang=\"ko-en\">Next Level</se><se lang=\"ko-en\"><w>Next<ana gr=\"NNP\" lang=\"en\" lex=\"Next\" transcr=\"Next\" /></w><w>Level<ana gr=\"NNP\" lang=\"en\" lex=\"Level\" transcr=\"Level\" /></w></se></para id=\"11-5\"><para id=\"11-6\"><se lang=\"ru\">Я чувствую себя зверем</se><se lang=\"ko-en\">야수 같은 나를 느껴</se><se lang=\"ko-en\"><w>야수<ana gr=\"NNG\" lang=\"ko\" lex=\"야수\" transcr=\"yasu\" /></w><w>같<ana gr=\"VA\" lang=\"ko\" lex=\"같\" transcr=\"gat\" /></w><w>은<ana gr=\"ETD\" lang=\"ko\" lex=\"은\" transcr=\"eun\" /></w><w>나<ana gr=\"NP\" lang=\"ko\" lex=\"나\" transcr=\"na\" /></w><w>를<ana gr=\"JKO\" lang=\"ko\" lex=\"를\" transcr=\"reul\" /></w><w>느끼<ana gr=\"VV\" lang=\"ko\" lex=\"느끼\" transcr=\"neukki\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w></se></para id=\"11-6\"><para id=\"11-7\"><se lang=\"ru\">Следующий уровень</se><se lang=\"ko-en\">Next Level</se><se lang=\"ko-en\"><w>Next<ana gr=\"NNP\" lang=\"en\" lex=\"Next\" transcr=\"Next\" /></w><w>Level<ana gr=\"NNP\" lang=\"en\" lex=\"Level\" transcr=\"Level\" /></w></se></para id=\"11-7\"><para id=\"11-8\"><se lang=\"ru\">Я побежу, побежу, побежу</se><se lang=\"ko-en\">제껴라 제껴라 제껴라</se><se lang=\"ko-en\"><w>제끼<ana gr=\"VV\" lang=\"ko\" lex=\"제끼\" transcr=\"jekki\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w><w>라<ana gr=\"NNG\" lang=\"ko\" lex=\"라\" transcr=\"ra\" /></w><w>제끼<ana gr=\"VV\" lang=\"ko\" lex=\"제끼\" transcr=\"jekki\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w><w>라<ana gr=\"NNG\" lang=\"ko\" lex=\"라\" transcr=\"ra\" /></w><w>제끼<ana gr=\"VV\" lang=\"ko\" lex=\"제끼\" transcr=\"jekki\" /></w><w>어<ana gr=\"ECS\" lang=\"ko\" lex=\"어\" transcr=\"eo\" /></w><w>라<ana gr=\"NNG\" lang=\"ko\" lex=\"라\" transcr=\"ra\" /></w></se></para id=\"11-8\"><para id=\"11-9\"><se lang=\"ru\">Хм!</se><se lang=\"ko-en\">Huh!</se><se lang=\"ko-en\"><w>Huh<ana gr=\"NNP\" lang=\"en\" lex=\"Huh\" transcr=\"Huh\" /></w><w>!<ana gr=\"punct\" lang=\"none\" lex=\"!\" transcr=\"!\" /></w></se></para id=\"11-9\"></body>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree = ET.ElementTree(xml_page)\n",
        "tree.write(\"Next Level by aespa (에스파)\" + \".xml\", \n",
        "           xml_declaration=True, encoding='utf-8')"
      ],
      "metadata": {
        "id": "I5AtRftmdTLI"
      },
      "id": "I5AtRftmdTLI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Комментарии"
      ],
      "metadata": {
        "id": "J5eZ19K5NS06"
      },
      "id": "J5eZ19K5NS06"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Проблема** с романизатором: вот такая морфема, например, не бывает на конце слова. Однако из-за структуры морфологического анализатора в транслитератор подаётся именно такой слог, и он не понимает как его читать. Как быть? Как вариант, можно попробовать придумать свои правила хехе, слогов с двумя согласными на конце не так уж много."
      ],
      "metadata": {
        "id": "Gm1Q9N840mPS"
      },
      "id": "Gm1Q9N840mPS"
    },
    {
      "cell_type": "code",
      "source": [
        "transcr = Romanizer('않')\n",
        "transcr = transcr.romanize()\n",
        "print(transcr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "VzDCpB5YzIcd",
        "outputId": "2bac3481-f323-4749-9a4e-eabab260ee38"
      },
      "id": "VzDCpB5YzIcd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-bf404c8ecb7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtranscr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRomanizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'않'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtranscr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mromanize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/korean_romanizer/romanizer.py\u001b[0m in \u001b[0;36mromanize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mromanize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mpronounced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPronouncer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpronounced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mhangul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"[가-힣ㄱ-ㅣ]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0m_romanized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/korean_romanizer/pronouncer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_syllables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mSyllable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpronounced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_substitute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/korean_romanizer/pronouncer.py\u001b[0m in \u001b[0;36mfinal_substitute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;31m# 6. 겹받침이 모음으로 시작된 조사나 어미, 접미사와 결합되는 경우에는,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# 뒤엣것만을 뒤 음절 첫소리로 옮겨 발음한다.(이 경우, ‘ㅅ’은 된소리로 발음함.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0msyllable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdouble_consonant_final\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnext_syllable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mNULL_CONSONANT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                 \u001b[0mdouble_consonant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdouble_consonant_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msyllable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0msyllable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdouble_consonant\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'initial'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "colab": {
      "name": "K-pop songs analizer part 2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6xR9bka-iNdl",
        "7bd0be0f",
        "Ktru55gh8R78",
        "Ifc0mrbSD29X",
        "6BOiv4QZq3XD",
        "SalyawIaLDQs",
        "M5P9sN-K6g9b",
        "J5eZ19K5NS06"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
